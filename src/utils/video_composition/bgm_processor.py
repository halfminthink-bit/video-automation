"""BGMã‚’å‡¦ç†ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""

import subprocess
from pathlib import Path
from typing import List, Dict, Optional, Tuple


class BGMProcessor:
    """
    BGMã®å‡¦ç†ã‚’æ‹…å½“
    
    æ©Ÿèƒ½:
    - ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚£ãƒ«ã‚¿ç”Ÿæˆ
    - BGMã®ãƒ«ãƒ¼ãƒ—ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°
    - ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆ
    - éŸ³é‡èª¿æ•´
    """
    
    def __init__(
        self,
        project_root: Path,
        logger,
        bgm_fade_in: float = 3.0,
        bgm_fade_out: float = 3.0
    ):
        """
        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
            logger: ãƒ­ã‚¬ãƒ¼
            bgm_fade_in: ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³æ™‚é–“ï¼ˆç§’ï¼‰
            bgm_fade_out: ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.project_root = project_root
        self.logger = logger
        self.bgm_fade_in = bgm_fade_in
        self.bgm_fade_out = bgm_fade_out
    
    def get_audio_duration(self, audio_path: Path) -> float:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
        Returns:
            éŸ³å£°ã®é•·ã•ï¼ˆç§’ï¼‰
        """
        try:
            # ffprobe ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—
            cmd = [
                'ffprobe', '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                str(audio_path)
            ]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=False,  # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§
                check=True
            )
            duration_str = result.stdout.decode('utf-8', errors='ignore').strip()
            duration = float(duration_str)
            self.logger.debug(f"Audio duration ({audio_path.name}): {duration:.2f}s")
            return duration
        except Exception as e:
            self.logger.warning(f"Failed to get audio duration: {e}")
            return 10.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def build_audio_filter(
        self, 
        bgm_segments: List[dict], 
        narration_input: int = 1,
        bgm_input_start: int = 2
    ) -> str:
        """
        BGMãƒŸãƒƒã‚¯ã‚¹ç”¨ã®ffmpegãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”Ÿæˆï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®éŸ³é‡å¯¾å¿œï¼‰

        æˆ¦ç•¥:
        1. å„BGMã‚’ãƒ«ãƒ¼ãƒ—ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°
        2. anullsrcã§å‰ã«ç„¡éŸ³ã‚’è¿½åŠ 
        3. concatã§çµåˆ
        4. å„BGMã«å€‹åˆ¥ã®éŸ³é‡ã‚’é©ç”¨
        5. å…¨BGMã‚’amixã§ãƒŸãƒƒã‚¯ã‚¹
        6. ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒŸãƒƒã‚¯ã‚¹
        
        Args:
            bgm_segments: BGMã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ
            narration_input: ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã®å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰
            bgm_input_start: BGMã®é–‹å§‹å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
        
        Returns:
            FFmpegãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ–‡å­—åˆ—
        """
        filters = []

        self.logger.info("=" * 60)
        self.logger.info("Building audio filter:")
        self.logger.info(f"  BGM segments: {len(bgm_segments)}")
        self.logger.info(f"  Narration input: {narration_input}, BGM start: {bgm_input_start}")

        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        filters.append(f"[{narration_input}:a]volume=1.0[narration]")

        # å„BGMã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        bgm_outputs = []
        for i, segment in enumerate(bgm_segments):
            input_idx = bgm_input_start + i  # BGMã®å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            start_time = segment.get('start_time', 0)
            duration = segment.get('duration', 0)
            fade_in = segment.get('fade_in', self.bgm_fade_in)
            fade_out = segment.get('fade_out', self.bgm_fade_out)
            bgm_volume = segment.get('volume', 0.13)  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®éŸ³é‡ã‚’å–å¾—

            # BGMãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿéš›ã®é•·ã•ã‚’å–å¾—
            bgm_path = Path(segment.get('file_path', ''))
            if bgm_path.exists():
                bgm_actual_duration = self.get_audio_duration(bgm_path)
            else:
                bgm_actual_duration = 30.0

            self.logger.info(
                f"  BGM {i+1} ({segment.get('bgm_type')}): "
                f"start={start_time:.1f}s, duration={duration:.1f}s, "
                f"bgm_length={bgm_actual_duration:.1f}s, "
                f"volume={bgm_volume:.1%}"
            )

            # Step 1: BGMã‚’ãƒ«ãƒ¼ãƒ—ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°
            if duration > bgm_actual_duration:
                loop_count = int(duration / bgm_actual_duration) + 2
                bgm_part = (
                    f"[{input_idx}:a]"
                    f"aloop=loop={loop_count}:size={int(bgm_actual_duration * 48000)},"
                    f"atrim=0:{duration},"
                    f"asetpts=PTS-STARTPTS"
                    f"[bgm{i}_trimmed]"
                )
                self.logger.info(f"    Looping {loop_count} times")
            else:
                bgm_part = (
                    f"[{input_idx}:a]"
                    f"atrim=0:{min(duration, bgm_actual_duration)},"
                    f"asetpts=PTS-STARTPTS"
                    f"[bgm{i}_trimmed]"
                )

            filters.append(bgm_part)

            # Step 2: ãƒ•ã‚§ãƒ¼ãƒ‰é©ç”¨
            fade_part = (
                f"[bgm{i}_trimmed]"
                f"afade=t=in:st=0:d={fade_in},"
                f"afade=t=out:st={duration - fade_out}:d={fade_out},"
                f"volume={bgm_volume:.3f}"
                f"[bgm{i}_faded]"
            )
            filters.append(fade_part)

            # Step 3: å‰ã«ç„¡éŸ³ã‚’è¿½åŠ ï¼ˆanullsrc + concatï¼‰
            if start_time > 0:
                silence_part = (
                    f"anullsrc=channel_layout=stereo:sample_rate=48000:duration={start_time}"
                    f"[silence{i}];"
                    f"[silence{i}][bgm{i}_faded]concat=n=2:v=0:a=1"
                    f"[bgm{i}]"
                )
                self.logger.info(f"    Adding {start_time:.1f}s silence before BGM")
            else:
                silence_part = f"[bgm{i}_faded]acopy[bgm{i}]"

            filters.append(silence_part)
            bgm_outputs.append(f'[bgm{i}]')

        # Step 4: å…¨BGMã‚’ãƒŸãƒƒã‚¯ã‚¹
        if len(bgm_outputs) > 1:
            bgm_mix = f"{''.join(bgm_outputs)}amix=inputs={len(bgm_outputs)}:duration=longest:dropout_transition=0[bgm_all]"
            filters.append(bgm_mix)
            self.logger.info(f"  Mixing {len(bgm_outputs)} BGM tracks")

            # Step 5: ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒŸãƒƒã‚¯ã‚¹ï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é•·ã•ã«åˆã‚ã›ã‚‹ï¼‰
            final_mix = "[narration][bgm_all]amix=inputs=2:duration=first:dropout_transition=3[audio]"
        else:
            if len(bgm_outputs) == 1:
                # BGMãŒ1ã¤ã®ã¿ã®å ´åˆ
                final_mix = "[narration][bgm0]amix=inputs=2:duration=first:dropout_transition=3[audio]"
            else:
                # BGMãŒãªã„å ´åˆ
                final_mix = "[narration]acopy[audio]"

        filters.append(final_mix)

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’çµåˆ
        audio_filter = ";".join(filters)
        return audio_filter
    
    def create_bgm_filter_for_background(
        self,
        bgm_data: dict,
        audio_path: Path,
        num_bg_videos: int = 0,
        sfx_inputs: List[dict] = None,
        title_segments: List[dict] = None,
        bgm_volume_multiplier: float = 1.0
    ) -> Tuple[str, List[str]]:
        """
        BGMãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½œæˆï¼ˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åŸºã¥ã„ãŸåˆ‡ã‚Šæ›¿ãˆå¯¾å¿œã€åŠ¹æœéŸ³ã¨ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã®éŸ³é‡èª¿æ•´å¯¾å¿œï¼‰

        Args:
            bgm_data: {"segments": [...]} å½¢å¼
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            num_bg_videos: èƒŒæ™¯å‹•ç”»ã®æ•°ï¼ˆBGMãƒ•ã‚¡ã‚¤ãƒ«ã®å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨ˆç®—ç”¨ï¼‰
            sfx_inputs: åŠ¹æœéŸ³ã®å…¥åŠ›æƒ…å ±ãƒªã‚¹ãƒˆ
            title_segments: ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã®ãƒªã‚¹ãƒˆ
            bgm_volume_multiplier: ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã§ã®BGMéŸ³é‡å€ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰

        Returns:
            (bgm_filter, bgm_map) ã‚¿ãƒ—ãƒ«
        """
        if not bgm_data or not bgm_data.get('segments'):
            # éŸ³å£°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ±ºå®š
            if num_bg_videos == 0:
                return "", ['-map', '2:a']  # [2] = éŸ³å£°ï¼ˆèƒŒæ™¯å‹•ç”»ãŒäº‹å‰å‡¦ç†æ¸ˆã¿ï¼‰
            else:
                return "", ['-map', '1:a']  # [1] = éŸ³å£°ï¼ˆæ—§å®Ÿè£…ï¼‰
        
        bgm_segments = bgm_data.get('segments', [])
        filters = []
        
        self.logger.info("=" * 60)
        self.logger.info("Building BGM filter for background video:")
        self.logger.info(f"  BGM segments: {len(bgm_segments)}")
        self.logger.info(f"  Background videos: {num_bg_videos}")
        
        # å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨ˆç®—:
        # num_bg_videos=0 ã®å ´åˆï¼ˆèƒŒæ™¯å‹•ç”»ãŒäº‹å‰å‡¦ç†æ¸ˆã¿ï¼‰:
        #   [0] = èƒŒæ™¯å‹•ç”»ï¼ˆconcatï¼‰, [1] = ç”»åƒï¼ˆconcatï¼‰, [2] = éŸ³å£°, [3]ä»¥é™ = BGM
        # num_bg_videos>0 ã®å ´åˆï¼ˆèƒŒæ™¯å‹•ç”»ãŒå€‹åˆ¥å…¥åŠ›ï¼‰:
        #   [0] = ç”»åƒ, [1] = éŸ³å£°, [2]ä»¥é™ = èƒŒæ™¯å‹•ç”», ãã®å¾Œ = BGM
        
        if num_bg_videos == 0:
            # èƒŒæ™¯å‹•ç”»ãŒäº‹å‰å‡¦ç†æ¸ˆã¿ã®å ´åˆ
            audio_input_idx = 2  # [2] = éŸ³å£°
            bgm_start_index = 3  # [3]ä»¥é™ = BGM
        else:
            # èƒŒæ™¯å‹•ç”»ãŒå€‹åˆ¥å…¥åŠ›ã®å ´åˆï¼ˆæ—§å®Ÿè£…ã¨ã®äº’æ›æ€§ï¼‰
            audio_input_idx = 1  # [1] = éŸ³å£°
            bgm_start_index = 2 + num_bg_videos  # [2+num_bg_videos]ä»¥é™ = BGM
        
        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        filters.append(f"[{audio_input_idx}:a]volume=1.0[narration]")
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªBGMãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¤‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ä½¿ã‚ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
        bgm_files_map = {}  # {file_path: input_index}
        current_bgm_index = bgm_start_index
        
        seen_files = set()
        for segment in bgm_segments:
            file_path = segment.get('file_path')
            if file_path and file_path not in seen_files:
                bgm_files_map[file_path] = current_bgm_index
                seen_files.add(file_path)
                current_bgm_index += 1
        
        # å„BGMã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        bgm_outputs = []
        for i, segment in enumerate(bgm_segments):
            file_path = segment.get('file_path')
            if not file_path:
                continue
            
            # ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ä½¿ç”¨ã™ã‚‹BGMãƒ•ã‚¡ã‚¤ãƒ«ã®å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            bgm_input_idx = bgm_files_map.get(file_path)
            if bgm_input_idx is None:
                continue
            
            start_time = segment.get('start_time', 0)
            duration = segment.get('duration', 0)
            fade_in = segment.get('fade_in', self.bgm_fade_in)
            fade_out = segment.get('fade_out', self.bgm_fade_out)
            bgm_volume = segment.get('volume', 0.13)  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®éŸ³é‡ã‚’å–å¾—
            
            # BGMãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿéš›ã®é•·ã•ã‚’å–å¾—
            bgm_path = Path(file_path)
            if not bgm_path.is_absolute():
                bgm_path = self.project_root / bgm_path
            
            if bgm_path.exists():
                bgm_actual_duration = self.get_audio_duration(bgm_path)
            else:
                bgm_actual_duration = 30.0
                self.logger.warning(f"BGM file not found: {bgm_path}, using default duration")
            
            self.logger.info(
                f"  BGM {i+1} ({segment.get('bgm_type', 'unknown')}): "
                f"start={start_time:.1f}s, duration={duration:.1f}s, "
                f"bgm_length={bgm_actual_duration:.1f}s, "
                f"volume={bgm_volume:.1%}"
            )
            
            # Step 1: BGMã‚’ãƒ«ãƒ¼ãƒ—ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°
            if duration > bgm_actual_duration:
                loop_count = int(duration / bgm_actual_duration) + 2
                bgm_part = (
                    f"[{bgm_input_idx}:a]"
                    f"aloop=loop={loop_count}:size={int(bgm_actual_duration * 48000)},"
                    f"atrim=0:{duration},"
                    f"asetpts=PTS-STARTPTS"
                    f"[bgm{i}_trimmed]"
                )
                self.logger.info(f"    Looping {loop_count} times")
            else:
                bgm_part = (
                    f"[{bgm_input_idx}:a]"
                    f"atrim=0:{min(duration, bgm_actual_duration)},"
                    f"asetpts=PTS-STARTPTS"
                    f"[bgm{i}_trimmed]"
                )
            
            filters.append(bgm_part)

            # Step 2: ãƒ•ã‚§ãƒ¼ãƒ‰é©ç”¨ + ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã®éŸ³é‡èª¿æ•´
            # ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã§ã®éŸ³é‡èª¿æ•´å¼ã‚’ç”Ÿæˆ
            if title_segments and bgm_volume_multiplier != 1.0:
                # å‹•çš„éŸ³é‡å¼ã‚’ç”Ÿæˆ
                volume_expr = f"{bgm_volume:.3f}"

                # ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã§ã¯éŸ³é‡ã‚’ä¸‹ã’ã‚‹
                for seg in title_segments:
                    # ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚é–“ã§åˆ¤å®šï¼ˆstart_timeã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ï¼‰
                    seg_start_global = start_time + seg['start']
                    seg_end_global = start_time + seg['end']

                    # ã“ã®BGMã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ãŒé‡ãªã‚‹å ´åˆã®ã¿é©ç”¨
                    bgm_end = start_time + duration
                    if seg_start_global < bgm_end and seg_end_global > start_time:
                        # ãƒ­ãƒ¼ã‚«ãƒ«æ™‚é–“ã«å¤‰æ›ï¼ˆã“ã®BGMã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã§ã®æ™‚é–“ï¼‰
                        local_start = max(0, seg['start'] - start_time)
                        local_end = min(duration, seg['end'] - start_time)

                        if local_start < duration and local_end > 0:
                            adjusted_volume = bgm_volume * bgm_volume_multiplier
                            volume_expr = (
                                f"if(between(t,{local_start:.3f},{local_end:.3f}),"
                                f"{adjusted_volume:.3f},"
                                f"{volume_expr})"
                            )

                fade_part = (
                    f"[bgm{i}_trimmed]"
                    f"afade=t=in:st=0:d={fade_in},"
                    f"afade=t=out:st={duration - fade_out}:d={fade_out},"
                    f"volume='{volume_expr}'"
                    f"[bgm{i}_faded]"
                )
            else:
                # ã‚¿ã‚¤ãƒˆãƒ«åŒºé–“ã®éŸ³é‡èª¿æ•´ãªã—
                fade_part = (
                    f"[bgm{i}_trimmed]"
                    f"afade=t=in:st=0:d={fade_in},"
                    f"afade=t=out:st={duration - fade_out}:d={fade_out},"
                    f"volume={bgm_volume:.3f}"
                    f"[bgm{i}_faded]"
                )

            filters.append(fade_part)
            
            # Step 3: å‰ã«ç„¡éŸ³ã‚’è¿½åŠ ï¼ˆanullsrc + concatï¼‰
            if start_time > 0:
                silence_part = (
                    f"anullsrc=channel_layout=stereo:sample_rate=48000:duration={start_time}"
                    f"[silence{i}];"
                    f"[silence{i}][bgm{i}_faded]concat=n=2:v=0:a=1"
                    f"[bgm{i}]"
                )
                self.logger.info(f"    Adding {start_time:.1f}s silence before BGM")
            else:
                silence_part = f"[bgm{i}_faded]acopy[bgm{i}]"
            
            filters.append(silence_part)
            bgm_outputs.append(f'[bgm{i}]')
        
        # Step 4: å…¨BGMã‚’ãƒŸãƒƒã‚¯ã‚¹
        if len(bgm_outputs) > 1:
            bgm_mix = f"{''.join(bgm_outputs)}amix=inputs={len(bgm_outputs)}:duration=longest:dropout_transition=0[bgm_all]"
            filters.append(bgm_mix)
            self.logger.info(f"  Mixing {len(bgm_outputs)} BGM tracks")
        elif len(bgm_outputs) == 1:
            # BGMãŒ1ã¤ã®ã¿ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
            filters.append("[bgm0]acopy[bgm_all]")

        # Step 5: åŠ¹æœéŸ³ã‚’å‡¦ç†
        sfx_outputs = []
        if sfx_inputs:
            # åŠ¹æœéŸ³ã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
            sfx_start_index = bgm_start_index + len(bgm_files_map)

            for i, sfx in enumerate(sfx_inputs):
                sfx_input_idx = sfx_start_index  # ã™ã¹ã¦ã®åŠ¹æœéŸ³ãŒåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                start_time = sfx['start_time']
                volume = sfx.get('volume', 0.5)
                fade_in = sfx.get('fade_in', 0.05)
                fade_out = sfx.get('fade_out', 0.1)

                # ğŸ” ãƒ‡ãƒãƒƒã‚°: åŠ¹æœéŸ³ã®è©³ç´°æƒ…å ±
                self.logger.info(f"  ğŸ”Š [DEBUG] SFX {i+1}: start={start_time:.2f}s, volume={volume}, fade_in={fade_in}s, fade_out={fade_out}s")

                # åŠ¹æœéŸ³ã®å‡¦ç†ï¼ˆãƒ•ã‚§ãƒ¼ãƒ‰ + éŸ³é‡èª¿æ•´ï¼‰
                sfx_filter = (
                    f"[{sfx_input_idx}:a]"
                    f"afade=t=in:st=0:d={fade_in},"
                    f"afade=t=out:st=0.5:d={fade_out},"
                    f"volume={volume}"
                    f"[sfx{i}_faded];"
                )

                # ç„¡éŸ³ã‚’è¿½åŠ ã—ã¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°èª¿æ•´
                sfx_filter += (
                    f"anullsrc=channel_layout=stereo:sample_rate=48000:duration={start_time}"
                    f"[silence_sfx{i}];"
                    f"[silence_sfx{i}][sfx{i}_faded]concat=n=2:v=0:a=1"
                    f"[sfx{i}]"
                )

                filters.append(sfx_filter)
                sfx_outputs.append(f'[sfx{i}]')

            self.logger.info(f"  Added {len(sfx_outputs)} sound effects")

        # Step 6: æœ€çµ‚ãƒŸãƒƒã‚¯ã‚¹ï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ + BGM + åŠ¹æœéŸ³ï¼‰
        all_inputs = ['[narration]']

        if bgm_outputs:
            all_inputs.append('[bgm_all]')

        if sfx_outputs:
            all_inputs.extend(sfx_outputs)

        if len(all_inputs) > 1:
            final_mix = f"{''.join(all_inputs)}amix=inputs={len(all_inputs)}:duration=first:dropout_transition=3[audio]"
        else:
            final_mix = "[narration]acopy[audio]"

        filters.append(final_mix)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’çµåˆ
        bgm_filter = ";" + ";".join(filters)
        bgm_map = ['-map', '[audio]']
        
        return bgm_filter, bgm_map


