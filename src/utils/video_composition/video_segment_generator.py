"""
å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

ç”»åƒã‹ã‚‰å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã€æœ€çµ‚å‹•ç”»ã‚’ä½œæˆã™ã‚‹å°‚é–€ã‚¯ãƒ©ã‚¹
"""

import json
import random
import re
import subprocess
import tempfile
from pathlib import Path
from typing import List, Dict, Optional, Any

from ...core.config_manager import ConfigManager


class VideoSegmentGenerator:
    """
    å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

    è²¬ä»»:
    - ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®è¨ˆç®—ï¼ˆLLMã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã€å‡ç­‰åˆ†å‰²ï¼‰
    - ç”»åƒã‹ã‚‰å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç”Ÿæˆï¼ˆã‚ºãƒ¼ãƒ åŠ¹æœä»˜ãï¼‰
    - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é€£çµ
    - BGMãƒ»éŸ³å£°ã®çµ±åˆ
    """

    def __init__(
        self,
        config: ConfigManager,
        logger,
        working_dir: Path,
        phase_dir: Path,
        phase_config: Optional[Dict] = None,
        encode_preset: str = "ultrafast"
    ):
        """
        åˆæœŸåŒ–

        Args:
            config: ConfigManager ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            logger: ãƒ­ã‚¬ãƒ¼
            working_dir: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            phase_dir: ãƒ•ã‚§ãƒ¼ã‚ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            phase_config: Phaseè¨­å®š
            encode_preset: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ—ãƒªã‚»ãƒƒãƒˆ
        """
        self.config = config
        self.logger = logger
        self.working_dir = working_dir
        self.phase_dir = phase_dir
        self.phase_config = phase_config or {}
        self.encode_preset = encode_preset

        # ä¾å­˜ã™ã‚‹ä»–ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µ
        from .bgm_processor import BGMProcessor
        from .ffmpeg_builder import FFmpegBuilder
        from .gradient_processor import GradientProcessor

        bgm_fade_in = 3.0
        bgm_fade_out = 3.0
        self.bgm_processor = BGMProcessor(
            config.project_root,
            logger,
            bgm_fade_in=bgm_fade_in,
            bgm_fade_out=bgm_fade_out
        )

        self.ffmpeg_builder = FFmpegBuilder(
            config.project_root,
            logger,
            encode_preset=encode_preset,
            threads=0,
            bgm_processor=self.bgm_processor
        )

        self.gradient_processor = GradientProcessor(
            logger=logger,
            working_dir=working_dir
        )

    def create_video_from_segments(
        self,
        audio_path: Path,
        script: dict,
        audio_timing: dict,
        bgm_data: Optional[dict] = None,
        output_path: Optional[Path] = None,
        ass_path: Optional[Path] = None
    ) -> Path:
        """
        ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰æœ€çµ‚å‹•ç”»ã‚’ç”Ÿæˆ

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            script: å°æœ¬ãƒ‡ãƒ¼ã‚¿
            audio_timing: éŸ³å£°ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
            bgm_data: BGMãƒ‡ãƒ¼ã‚¿
            output_path: å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ phase_dir/final_video.mp4ï¼‰
            ass_path: ASSå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ç”Ÿæˆã•ã‚Œãªã„ï¼‰

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã®ãƒ‘ã‚¹
        """
        if output_path is None:
            output_path = self.phase_dir / "final_video.mp4"

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®å‹•ç”»ç”Ÿæˆ
        video_path = self._create_segment_videos_then_concat(
            audio_path=audio_path,
            script=script,
            audio_timing=audio_timing,
            bgm_data=bgm_data,
            output_path=output_path,
            ass_path=ass_path
        )

        return video_path

    def calculate_image_timings(
        self,
        audio_path: Path,
        script: dict,
        audio_timing: dict,
        resolve_image_path_func
    ) -> List[dict]:
        """
        ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç®—ï¼ˆLLMã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã€å‡ç­‰åˆ†å‰²ã®3ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            script: å°æœ¬ãƒ‡ãƒ¼ã‚¿
            audio_timing: éŸ³å£°ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
            resolve_image_path_func: ç”»åƒãƒ‘ã‚¹è§£æ±ºé–¢æ•°

        Returns:
            ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ãƒªã‚¹ãƒˆ [{'path': Path, 'duration': float, 'depth_map_path': Optional[str]}, ...]
        """
        # 1. processed_images.jsonã‹ã‚‰ç”»åƒã‚’å–å¾—
        processed_json = self.working_dir / "04_processed" / "processed_images.json"
        all_images = []
        classified_data = None

        if processed_json.exists():
            try:
                self.logger.info(f"Loading processed images from {processed_json}")
                with open(processed_json, 'r', encoding='utf-8') as f:
                    processed_data = json.load(f)

                processed_images = processed_data.get('images', [])

                for img_data in processed_images:
                    processed_path_str = img_data.get('processed_file_path', '')
                    processed_path = resolve_image_path_func(processed_path_str)

                    if processed_path and processed_path.exists():
                        depth_map_path_str = img_data.get('depth_map_path', '')
                        depth_map_path = None
                        if depth_map_path_str:
                            depth_map_path = resolve_image_path_func(depth_map_path_str)
                            if depth_map_path and not depth_map_path.exists():
                                depth_map_path = None

                        all_images.append({
                            'file_path': str(processed_path),
                            'section_id': img_data.get('section_id'),
                            'image_id': img_data.get('image_id'),
                            'keywords': img_data.get('keywords', []),
                            'depth_map_path': str(depth_map_path) if depth_map_path else None
                        })
                        self.logger.debug(f"  Using processed image: {processed_path.name}")

                if all_images:
                    self.logger.info(f"âœ… Loaded {len(all_images)} processed images")
            except Exception as e:
                self.logger.warning(f"Failed to load processed_images.json: {e}, falling back to classified.json")
                all_images = []

        # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: classified.jsonã‹ã‚‰å…ƒç”»åƒã‚’å–å¾—
        if not all_images:
            classified_path = self.working_dir / "03_images" / "classified.json"
            if not classified_path.exists():
                raise FileNotFoundError(f"Neither processed_images.json nor classified.json found")

            self.logger.info(f"Loading images from {classified_path}")
            with open(classified_path, 'r', encoding='utf-8') as f:
                classified_data = json.load(f)

            all_images = classified_data.get('images', [])
            self.logger.info(f"âœ… Loaded {len(all_images)} images from classified.json")

        # 3. ã‚»ã‚¯ã‚·ãƒ§ãƒ³IDã¨æ™‚é–“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        section_durations = {}
        if isinstance(audio_timing, list):
            for timing_section in audio_timing:
                section_id = timing_section.get('section_id')
                if section_id:
                    total_duration = timing_section.get('total_duration')
                    if total_duration:
                        section_durations[section_id] = total_duration
                    else:
                        narration_timing = timing_section.get('narration_timing', {})
                        end_time = narration_timing.get('end_time')
                        if end_time:
                            section_durations[section_id] = end_time
                        else:
                            char_end_times = timing_section.get('char_end_times', [])
                            if char_end_times:
                                section_durations[section_id] = char_end_times[-1]
        elif isinstance(audio_timing, dict):
            sections = audio_timing.get('sections', [audio_timing])
            for timing_section in sections:
                section_id = timing_section.get('section_id')
                if section_id:
                    total_duration = timing_section.get('total_duration')
                    if total_duration:
                        section_durations[section_id] = total_duration
                    else:
                        narration_timing = timing_section.get('narration_timing', {})
                        end_time = narration_timing.get('end_time')
                        if end_time:
                            section_durations[section_id] = end_time
                        else:
                            char_end_times = timing_section.get('char_end_times', [])
                            if char_end_times:
                                section_durations[section_id] = char_end_times[-1]

        if section_durations:
            self.logger.info(f"âœ… Loaded {len(section_durations)} section durations")

        # 4. ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ç”»åƒã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        section_images = {sid: [] for sid in section_durations.keys()}
        image_info_map = {}

        for img in all_images:
            file_path = Path(img.get('file_path', ''))
            if not file_path.exists():
                continue

            section_num = img.get('section_id')
            if not section_num:
                match = re.search(r'section_(\d+)', file_path.name)
                if match:
                    section_num = int(match.group(1))
                else:
                    continue

            image_info_map[str(file_path)] = {
                'section_id': section_num,
                'depth_map_path': img.get('depth_map_path')
            }

            if section_num in section_images:
                section_images[section_num].append(file_path)

        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã§ã‚½ãƒ¼ãƒˆ
        for section_num in section_images.keys():
            section_images[section_num].sort(key=lambda p: p.name)

        # 5. ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆç®—ï¼ˆå‡ç­‰åˆ†å‰²ãƒ¢ãƒ¼ãƒ‰ï¼‰
        image_timings = []
        sorted_section_ids = sorted(section_images.keys())
        actual_audio_duration = self.bgm_processor.get_audio_duration(audio_path)
        self.logger.info(f"Actual audio duration: {actual_audio_duration:.3f}s")

        # å‡ç­‰åˆ†å‰²ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        self.logger.info("ğŸ“Š Using equal split image timing mode")
        for section_id in sorted_section_ids:
            images = section_images[section_id]
            if not images:
                continue

            section_duration = section_durations.get(section_id, 0)
            duration_per_image = section_duration / len(images) if images else 0

            for image_path in images:
                img_info = image_info_map.get(str(image_path), {})
                image_timings.append({
                    'path': image_path,
                    'duration': duration_per_image,
                    'section_id': img_info.get('section_id'),
                    'depth_map_path': img_info.get('depth_map_path')
                })

        self.logger.info(f"Total images to process: {len(image_timings)}")
        return image_timings

    def _create_segment_videos_then_concat(
        self,
        audio_path: Path,
        script: dict,
        audio_timing: dict,
        bgm_data: Optional[dict],
        output_path: Path,
        ass_path: Optional[Path] = None
    ) -> Path:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«å‹•ç”»ã‚’ä½œæˆã—ã¦ã‹ã‚‰é€£çµ

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            script: å°æœ¬ãƒ‡ãƒ¼ã‚¿
            audio_timing: éŸ³å£°ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
            bgm_data: BGMãƒ‡ãƒ¼ã‚¿
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            ass_path: ASSå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            æœ€çµ‚å‹•ç”»ã®ãƒ‘ã‚¹
        """
        self.logger.info("ğŸ¬ Using segment-based approach for better subtitle sync...")

        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        temp_dir = Path(tempfile.mkdtemp(prefix="video_segments_"))
        segment_files = []
        concat_list = None

        try:
            # ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆç®—ï¼ˆresolve_image_path ã¯ Phase07DataLoader ã‹ã‚‰æ¸¡ã™å¿…è¦ãŒã‚ã‚‹ï¼‰
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å®Ÿè£…
            def resolve_image_path(path_str):
                if not path_str:
                    return None
                path = Path(path_str)
                if path.exists():
                    return path
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
                try:
                    parts = Path(path_str).parts
                    if 'data' in parts:
                        idx = parts.index('data')
                        rel = Path(*parts[idx:])
                        abs_path = self.config.project_root / rel
                        if abs_path.exists():
                            return abs_path
                except:
                    pass
                return None

            image_timings = self.calculate_image_timings(
                audio_path=audio_path,
                script=script,
                audio_timing=audio_timing,
                resolve_image_path_func=resolve_image_path
            )

            if not image_timings:
                raise ValueError("No image timings calculated")

            # å„ç”»åƒã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‹•ç”»ã«å¤‰æ›ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
            self.logger.info(f"Creating {len(image_timings)} video segments...")
            for i, timing in enumerate(image_timings):
                img_path = timing['path']
                duration = timing['duration']
                depth_map_path = timing.get('depth_map_path')

                segment_file = temp_dir / f"segment_{i:04d}.mp4"
                self.logger.info(f"  [{i+1}/{len(image_timings)}] {img_path.name} ({duration:.2f}s)")

                # 2.5Då‡¦ç† or ã‚ºãƒ¼ãƒ å‡¦ç†ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
                depth_map = None
                if depth_map_path:
                    depth_map = Path(depth_map_path) if isinstance(depth_map_path, str) else depth_map_path
                    if not depth_map.exists():
                        depth_map = None
                
                if depth_map:
                    # 2.5Då‡¦ç†
                    from .depth_animator import DepthAnimator
                    depth_animator = DepthAnimator(logger=self.logger)
                    
                    temp_2_5d = temp_dir / f"segment_2_5d_{i:04d}.mp4"
                    self.logger.info(f"  ğŸ¬ 2.5D animation: {depth_map.name}")
                    success = depth_animator.create_animation(
                        image_path=img_path,
                        depth_path=depth_map,
                        duration=duration,
                        output_path=temp_2_5d,
                        movement_type="dolly_zoom"
                    )
                    
                    if success:
                        # 2.5Då‹•ç”»ã‚’æ­£è¦åŒ–ï¼ˆFFmpegã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯çµ±ä¸€ï¼‰
                        # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¯é©ç”¨ã›ãšã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ­£è¦åŒ–ã®ã¿
                        normalized_2_5d = temp_dir / f"segment_2_5d_norm_{i:04d}.mp4"
                        self.logger.info(f"  ğŸ”„ Normalizing 2.5D segment format...")
                        norm_cmd = [
                            'ffmpeg', '-y',
                            '-i', str(temp_2_5d),
                            '-c:v', 'libx264', '-preset', self.encode_preset, '-crf', '18',
                            '-pix_fmt', 'yuv420p', '-r', '30',
                            str(normalized_2_5d)
                        ]
                        if self._run_ffmpeg_safe(norm_cmd, timeout=300):
                            segment_file = normalized_2_5d
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                            if temp_2_5d.exists():
                                temp_2_5d.unlink()
                        else:
                            # æ­£è¦åŒ–å¤±æ•—æ™‚ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                            self.logger.warning(f"Normalization failed, using original 2.5D file")
                            segment_file = temp_2_5d
                    else:
                        # 2.5Då¤±æ•—æ™‚ã¯é€šå¸¸ã®ã‚ºãƒ¼ãƒ å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        self.logger.warning(f"2.5D failed, falling back to zoom for {img_path.name}")
                        self._create_zoompan_segment(
                            img_path=img_path,
                            duration=duration,
                            output_path=segment_file,
                            seed=i
                        )
                else:
                    # é€šå¸¸ã®ã‚ºãƒ¼ãƒ å‡¦ç†ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
                    self._create_zoompan_segment(
                        img_path=img_path,
                        duration=duration,
                        output_path=segment_file,
                        seed=i
                    )

                segment_files.append(segment_file)

            # concat.txt ç”Ÿæˆ
            concat_list = temp_dir / "concat.txt"
            self._create_concat_file_with_duration(
                segment_files=segment_files,
                image_timings=image_timings,
                output_path=concat_list
            )

            # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‚’ç”Ÿæˆï¼ˆæœ€çµ‚åˆæˆæ™‚ã«ä½¿ç”¨ï¼‰
            gradient_path = self.gradient_processor.create_gradient_image(
                width=1920,
                height=1080,
                gradient_ratio=0.35
            )
            self.logger.info(f"ğŸ¨ Gradient image ready: {gradient_path.name}")

            # ASSå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæ—¢ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°Noneï¼‰
            if ass_path is None:
                # ASSãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                default_ass_path = self.phase_dir / "subtitles.ass"
                if default_ass_path.exists():
                    ass_path = default_ass_path
                    self.logger.info(f"ğŸ“ Using existing ASS file: {ass_path.name}")
                else:
                    self.logger.warning("âš ï¸ ASS file not found, video will be created without subtitles")
                    ass_path = None

            # å‹•ç”»ã‚’é€£çµ + ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç‹¬ç«‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰ + éŸ³å£° + å­—å¹• + BGM
            cmd = self.ffmpeg_builder.build_ffmpeg_command_optimized(
                concat_file=concat_list,
                audio_path=audio_path,
                ass_path=ass_path,
                output_path=output_path,
                bgm_data=bgm_data,
                gradient_path=gradient_path
            )

            self.logger.info("ğŸ¬ Running final FFmpeg merge...")
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            self.logger.info(f"âœ… Video created: {output_path}")
            return output_path

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if temp_dir.exists():
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)

    def _create_zoompan_segment(
        self,
        img_path: Path,
        duration: float,
        output_path: Path,
        seed: int
    ):
        """
        4Kã‚ºãƒ¼ãƒ å‡¦ç†ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰

        Args:
            img_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            duration: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ï¼ˆç§’ï¼‰
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
        """
        random.seed(seed)
        move_type = random.choice(["zoom_in", "zoom_out", "pan_right", "pan_left"])

        fps = 30
        frames = int(duration * fps)
        zoom_speed = 0.0003

        # 4Kå‡¦ç†ç”¨ãƒ•ã‚£ãƒ«ã‚¿
        scale_4k = "scale=3840:2160:force_original_aspect_ratio=increase,crop=3840:2160"

        if move_type == "zoom_in":
            z_expr = f"z='min(zoom+{zoom_speed},{1.15})'"
            pos = "x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'"
        elif move_type == "zoom_out":
            z_expr = f"z='if(eq(on,0),{1.15},max(zoom-{zoom_speed},1.0))'"
            pos = "x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'"
        elif move_type == "pan_right":
            x_expr = f"x='(iw-iw/zoom)*(on/{frames})'"
            z_expr = "z='1.1'"
            pos = f"{x_expr}:y='ih/2-(ih/zoom/2)'"
        else:  # pan_left
            x_expr = f"x='(iw-iw/zoom)*(1-on/{frames})'"
            z_expr = "z='1.1'"
            pos = f"{x_expr}:y='ih/2-(ih/zoom/2)'"

        filter_complex = (
            # èƒŒæ™¯: è»½é‡æ“¬ä¼¼ãƒ–ãƒ©ãƒ¼ (1920 -> 192 -> 1920)
            f"[0:v]scale=192:108,scale=1920:1080:flags=bicubic,eq=brightness=-0.3[bg];"
            # å‰æ™¯: 4Kã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ« -> Zoompan -> 1080pãƒ€ã‚¦ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒˆ
            f"[0:v]{scale_4k},zoompan={z_expr}:d={frames}:{pos}:s=3840x2160:fps={fps},scale=1920:1080[fg];"
            # åˆæˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
            "[bg][fg]overlay=(W-w)/2:(H-h)/2,format=yuv420p[out]"
        )

        cmd = [
            'ffmpeg', '-y',
            '-loop', '1', '-i', str(img_path),
            '-t', f"{duration:.6f}",
            '-filter_complex', filter_complex,
            '-map', '[out]',
            '-c:v', 'libx264', '-preset', self.encode_preset, '-crf', '18',
            '-pix_fmt', 'yuv420p', '-r', '30',
            str(output_path)
        ]

        if not self._run_ffmpeg_safe(cmd, timeout=300):
            raise RuntimeError(f"Failed to create zoom segment: {img_path.name}")

    def _create_concat_file_with_duration(
        self,
        segment_files: List[Path],
        image_timings: List[dict],
        output_path: Path
    ) -> Path:
        """
        FFmpeg concatç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆdurationä»˜ãï¼‰

        Args:
            segment_files: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
            image_timings: ç”»åƒã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ
            output_path: å‡ºåŠ›ãƒ‘ã‚¹

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸconcatãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        concat_lines = []

        for i, (seg_file, timing) in enumerate(zip(segment_files, image_timings)):
            # ãƒ‘ã‚¹æ­£è¦åŒ–
            path_str = str(seg_file.resolve()).replace('\\', '/').replace("'", "'\\''")
            concat_lines.append(f"file '{path_str}'")

            # æœ€å¾Œä»¥å¤–ã¯durationæŒ‡å®š
            if i < len(segment_files) - 1:
                duration = timing['duration']
                concat_lines.append(f"duration {duration:.6f}")

            self.logger.debug(
                f"  Concat entry {i+1}: {seg_file.name} "
                f"(duration: {timing['duration']:.3f}s)"
            )

        # æœ€å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åº¦è¿½åŠ ï¼ˆffmpeg concatä»•æ§˜ï¼‰
        if segment_files:
            last_file = segment_files[-1]
            path_str = str(last_file.resolve()).replace('\\', '/').replace("'", "'\\''")
            concat_lines.append(f"file '{path_str}'")
            self.logger.debug(f"  Added final frame: {last_file.name} (no duration)")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(concat_lines))

        self.logger.info(f"ğŸ“„ concat.txt created with {len(concat_lines)} lines")
        return output_path

    def _verify_segment_duration(self, segment_path: Path, expected_duration: float) -> bool:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‹•ç”»ã®é•·ã•ã‚’æ¤œè¨¼

        Args:
            segment_path: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            expected_duration: æœŸå¾…ã•ã‚Œã‚‹é•·ã•ï¼ˆç§’ï¼‰

        Returns:
            æ¤œè¨¼ã«æˆåŠŸã—ãŸå ´åˆ True
        """
        try:
            cmd = [
                'ffprobe',
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                str(segment_path)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            actual_duration = float(result.stdout.strip())

            # è¨±å®¹èª¤å·®: Â±0.1ç§’
            tolerance = 0.1
            if abs(actual_duration - expected_duration) <= tolerance:
                return True
            else:
                self.logger.warning(
                    f"Duration mismatch: {segment_path.name} "
                    f"(expected: {expected_duration:.3f}s, actual: {actual_duration:.3f}s)"
                )
                return False

        except Exception as e:
            self.logger.error(f"Failed to verify segment duration: {e}")
            return False

    def _run_ffmpeg_safe(self, cmd: List[str], timeout: int = 600) -> bool:
        """
        å®‰å…¨ãªFFmpegå®Ÿè¡Œãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯é˜²æ­¢ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰

        Args:
            cmd: FFmpegã‚³ãƒãƒ³ãƒ‰ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ï¼‰
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            æˆåŠŸã—ãŸå ´åˆ True
        """
        try:
            # stdin, stdout, stderr å…¨ã¦ã‚’ DEVNULL ã«ã—ã¦ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã‚’é˜²ã
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                stdin=subprocess.DEVNULL,
                timeout=timeout
            )
            return True
        except subprocess.TimeoutExpired:
            self.logger.error(f"âŒ FFmpeg timed out after {timeout}s")
            return False
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ FFmpeg execution failed with code {e.returncode}")
            return False
