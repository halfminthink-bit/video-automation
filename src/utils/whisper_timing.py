"""
Whisperã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import tempfile

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    whisper = None

try:
    import stable_whisper
    STABLE_WHISPER_AVAILABLE = True
except ImportError:
    STABLE_WHISPER_AVAILABLE = False
    stable_whisper = None


class WhisperTimingExtractor:
    """Whisperã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—"""
    
    def __init__(
        self,
        model_name: str = "base",
        logger: Optional[logging.Logger] = None,
        language: str = "ja",
        use_stable_ts: bool = True,
        suppress_silence: bool = True,
        vad: bool = True,
        vad_threshold: float = 0.35
    ):
        """
        åˆæœŸåŒ–

        Args:
            model_name: Whisperãƒ¢ãƒ‡ãƒ«åï¼ˆtiny, base, small, medium, largeï¼‰
            logger: ãƒ­ã‚¬ãƒ¼
            language: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ"ja" = æ—¥æœ¬èªï¼‰
            use_stable_ts: stable-tsã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆç„¡éŸ³æŠ‘åˆ¶ã€ã‚®ãƒ£ãƒƒãƒ—èª¿æ•´ãŒæœ‰åŠ¹ï¼‰
            suppress_silence: ç„¡éŸ³åŒºé–“ã‚’æŠ‘åˆ¶ã™ã‚‹ã‹ï¼ˆstable-tsä½¿ç”¨æ™‚ã®ã¿ï¼‰
            vad: Voice Activity Detectionã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆstable-tsä½¿ç”¨æ™‚ã®ã¿ï¼‰
            vad_threshold: VADã®é–¾å€¤ï¼ˆ0-1ã€ä½ã„ã»ã©å³æ ¼ï¼‰
        """
        if not WHISPER_AVAILABLE:
            raise ImportError(
                "whisper package is required. "
                "Install with: pip install openai-whisper"
            )

        self.logger = logger or logging.getLogger(__name__)
        self.language = language
        self.use_stable_ts = use_stable_ts and STABLE_WHISPER_AVAILABLE
        self.suppress_silence = suppress_silence
        self.vad = vad
        self.vad_threshold = vad_threshold

        # stable-tsãŒåˆ©ç”¨å¯èƒ½ã ãŒã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯è­¦å‘Š
        if use_stable_ts and not STABLE_WHISPER_AVAILABLE:
            self.logger.warning(
                "stable-ts is not available. Falling back to standard Whisper. "
                "Install with: pip install stable-ts"
            )
            self.use_stable_ts = False

        model_type = "stable-ts" if self.use_stable_ts else "Whisper"
        self.logger.info(f"Loading {model_type} model: {model_name}")

        try:
            # CPUã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯FP32ã‚’ä½¿ç”¨ï¼ˆFP16ã¯GPUã®ã¿å¯¾å¿œï¼‰
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"

            if self.use_stable_ts:
                # stable-tsãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
                self.model = stable_whisper.load_model(model_name, device=device)
                self.logger.info(
                    f"stable-ts model loaded successfully on {device} "
                    f"(suppress_silence={suppress_silence}, vad={vad})"
                )
            else:
                # æ¨™æº–Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
                self.model = whisper.load_model(model_name, device=device)
                self.logger.info(f"Whisper model loaded successfully on {device}")
        except Exception as e:
            self.logger.error(f"Failed to load model: {e}")
            raise
    
    def extract_word_timings(
        self,
        audio_path: Path,
        text: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            text: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
            
        Returns:
            å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ:
            [
                {
                    "word": "ç¹”ç”°",
                    "start": 0.5,
                    "end": 0.8,
                    "probability": 0.95
                },
                ...
            ]
        """
        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        self.logger.info(f"Extracting word timings from: {audio_path}")
        
        try:
            # Whisperã§éŸ³å£°èªè­˜ï¼ˆword_timestamps=Trueã§å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—ï¼‰
            # CPUã§ã¯FP16ãŒä½¿ãˆãªã„ãŸã‚ã€fp16=Falseã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
            import torch
            fp16_enabled = torch.cuda.is_available()

            # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            transcribe_params = {
                "language": self.language,
                "word_timestamps": True,
                # initial_promptã¯ä½¿ç”¨ã—ãªã„ï¼ˆå…¨æ–‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ãŸã‚ï¼‰
                # Whisperã®ä»•æ§˜: initial_promptã¯ã€Œç›´å‰ã«è©±ã•ã‚ŒãŸå†…å®¹ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã€
                # æ¸¡ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œã‚‚ã†è©±ã—çµ‚ã‚ã£ãŸã€ã¨åˆ¤æ–­ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
                "fp16": fp16_enabled,
                # ğŸ”¥ ç´¯ç©ã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼ˆæœ€é‡è¦ï¼‰
                "condition_on_previous_text": False,
                "no_speech_threshold": 0.3,
                "logprob_threshold": -1.0,
                "compression_ratio_threshold": 2.4,
                "temperature": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],
                "beam_size": 5,
                "patience": 1.0,
                "length_penalty": 1.0,
                "suppress_tokens": "-1",
                "task": "transcribe"
            }

            # stable-tsä½¿ç”¨æ™‚ã¯è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
            if self.use_stable_ts:
                transcribe_params.update({
                    "suppress_silence": self.suppress_silence,
                    "vad": self.vad,
                    "vad_threshold": self.vad_threshold
                })
                self.logger.debug(
                    f"Using stable-ts with suppress_silence={self.suppress_silence}, "
                    f"vad={self.vad}, vad_threshold={self.vad_threshold}"
                )

            result = self.model.transcribe(str(audio_path), **transcribe_params)

            # ğŸ”¥ stable-tsä½¿ç”¨æ™‚ï¼šã‚®ãƒ£ãƒƒãƒ—èª¿æ•´ã§ç™ºè©±å¢ƒç•Œã‚’æœ€é©åŒ–
            if self.use_stable_ts:
                result = result.adjust_gaps(
                    duration_threshold=0.75,
                    one_section=True  # TTSéŸ³å£°æ¨å¥¨
                )
                self.logger.debug("Applied gap adjustment to transcription result")

            # ãƒ‡ãƒãƒƒã‚°: Whisperã®èªè­˜çµæœã‚’ç¢ºèª
            if self.use_stable_ts:
                # stable-ts: å±æ€§ã‚¢ã‚¯ã‚»ã‚¹
                recognized_text = result.text
                segments = result.segments
                self.logger.info(f"Whisper recognized text: {recognized_text}")
                self.logger.info(f"Number of segments: {len(segments)}")
                for i, seg in enumerate(segments):
                    segment_text = seg.text
                    words = seg.words if hasattr(seg, 'words') else []
                    # stable-tsã«ã¯no_speech_probãŒãªã„
                    self.logger.info(
                        f"  Segment {i}: {segment_text} "
                        f"({len(words)} words)"
                    )
            else:
                # é€šå¸¸ã®Whisper: è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹
                recognized_text = result.get('text', '')
                segments = result.get("segments", [])
                self.logger.info(f"Whisper recognized text: {recognized_text}")
                self.logger.info(f"Number of segments: {len(segments)}")
                for i, seg in enumerate(segments):
                    segment_text = seg.get("text", "")
                    words = seg.get("words", []) or []
                    no_speech_prob = seg.get("no_speech_prob", 0)
                    self.logger.info(
                        f"  Segment {i}: {segment_text} "
                        f"({len(words)} words, no_speech_prob={no_speech_prob:.3f})"
                    )
            
            # å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’æŠ½å‡º
            word_timings = []
            if self.use_stable_ts:
                # stable-ts: å±æ€§ã‚¢ã‚¯ã‚»ã‚¹
                for segment in result.segments:
                    if hasattr(segment, 'words') and segment.words:
                        for word in segment.words:
                            word_timings.append({
                                "word": word.word.strip(),
                                "start": word.start,
                                "end": word.end,
                                "probability": getattr(word, 'probability', 1.0)
                            })
                
                # æœ€çµ‚æ™‚åˆ»ã®å–å¾—
                last_duration = result.segments[-1].end if result.segments else 0
                self.logger.info(
                    f"Extracted {len(word_timings)} word timings from stable-ts "
                    f"(duration: {last_duration:.1f}s)"
                )
            else:
                # é€šå¸¸ã®Whisper: è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹
                for segment in result.get("segments", []):
                    for word_info in segment.get("words", []):
                        word_timings.append({
                            "word": word_info.get("word", "").strip(),
                            "start": word_info.get("start", 0.0),
                            "end": word_info.get("end", 0.0),
                            "probability": word_info.get("probability", 1.0)
                        })
                
                last_duration = result.get('segments', [{}])[-1].get('end', 0) if result.get('segments') else 0
                self.logger.info(
                    f"Extracted {len(word_timings)} word timings from Whisper "
                    f"(duration: {last_duration:.1f}s)"
                )

            # ğŸ”¥ æ–°æ©Ÿèƒ½ï¼šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œ
            if text:
                self.logger.info("Aligning timings with original text...")
                
                # èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
                if self.use_stable_ts:
                    recognized_text = result.text
                else:
                    recognized_text = result.get('text', '')
                
                aligned_timings = align_text_with_whisper_timings(
                    original_text=text,
                    recognized_text=recognized_text,
                    word_timings=word_timings,
                    logger=self.logger
                )
                self.logger.info(
                    f"âœ“ Alignment complete: {len(aligned_timings)} characters mapped"
                )
                return aligned_timings
            else:
                # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆã¯ã€èªè­˜çµæœã‚’ãã®ã¾ã¾è¿”ã™
                return word_timings
            
        except Exception as e:
            self.logger.error(f"Failed to extract word timings: {e}", exc_info=True)
            raise
    
    def extract_sentence_timings(
        self,
        audio_path: Path,
        sentences: List[str],
        word_timings: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ–‡ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
        
        å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‹ã‚‰ã€å„æ–‡ã®é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            sentences: æ–‡ã®ãƒªã‚¹ãƒˆ
            word_timings: äº‹å‰ã«å–å¾—ã—ãŸå˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ï¼ˆNoneã®å ´åˆã¯å–å¾—ï¼‰
            
        Returns:
            æ–‡ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ:
            [
                {
                    "sentence": "ç¹”ç”°ä¿¡é•·ã¯...",
                    "start": 0.5,
                    "end": 3.2
                },
                ...
            ]
        """
        if word_timings is None:
            # å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
            word_timings = self.extract_word_timings(audio_path)
        
        if not word_timings:
            self.logger.warning("No word timings available, returning empty list")
            return []
        
        # å„æ–‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç®—
        sentence_timings = []
        current_word_idx = 0
        total_words = len(word_timings)
        
        for sentence_idx, sentence in enumerate(sentences):
            if not sentence.strip():
                continue
            
            # æ–‡ã®æ–‡å­—æ•°ã‚’è¨ˆç®—ï¼ˆæ—¥æœ¬èªã®å ´åˆã€æ–‡å­—æ•°ã§å¤§ä½“ã®é•·ã•ã‚’æ¨å®šï¼‰
            sentence_length = len(sentence)
            
            # ã“ã®æ–‡ã«å¯¾å¿œã™ã‚‹å˜èªæ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼šæ–‡å­—æ•°ã®æ¯”ç‡ï¼‰
            # å®Ÿéš›ã®éŸ³å£°èªè­˜çµæœã¨å°æœ¬ã®æ–‡å­—æ•°ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
            # ç´¯ç©æ–‡å­—æ•°ã‹ã‚‰æ¨å®š
            total_sentence_chars = sum(len(s) for s in sentences)
            if total_sentence_chars > 0:
                char_ratio = sentence_length / total_sentence_chars
                estimated_words = int(total_words * char_ratio)
            else:
                estimated_words = max(1, sentence_length // 2)  # 1æ–‡å­— = 0.5å˜èªï¼ˆæ¨å®šï¼‰
            
            # é–‹å§‹ä½ç½®ã‚’æ±ºå®š
            sentence_start = None
            sentence_end = None
            
            # ç¾åœ¨ã®ä½ç½®ã‹ã‚‰é–‹å§‹ã—ã¦ã€å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—
            words_for_sentence = min(estimated_words, total_words - current_word_idx)
            
            if words_for_sentence > 0 and current_word_idx < total_words:
                # ã“ã®æ–‡ã«å¯¾å¿œã™ã‚‹å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—
                sentence_start = word_timings[current_word_idx]["start"]
                sentence_end = word_timings[min(
                    current_word_idx + words_for_sentence - 1,
                    total_words - 1
                )]["end"]
                
                # æ¬¡ã®æ–‡ã®é–‹å§‹ä½ç½®ã‚’æ›´æ–°
                current_word_idx += words_for_sentence
            else:
                # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å‰ã®æ–‡ã®çµ‚äº†æ™‚é–“ã‚’ä½¿ç”¨
                if sentence_timings:
                    last_end = sentence_timings[-1]["end"]
                    # æ¨å®šæ™‚é–“ã‚’è¨ˆç®—ï¼ˆæ–‡å­—æ•°ã‹ã‚‰ï¼‰
                    estimated_duration = len(sentence) * 0.15  # 1æ–‡å­— = 0.15ç§’ï¼ˆæ¨å®šï¼‰
                    sentence_start = last_end
                    sentence_end = last_end + estimated_duration
                else:
                    # æœ€åˆã®æ–‡ã§ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
                    sentence_start = 0.0
                    estimated_duration = len(sentence) * 0.15
                    sentence_end = estimated_duration
            
            if sentence_start is not None and sentence_end is not None:
                sentence_timings.append({
                    "sentence": sentence,
                    "start": sentence_start,
                    "end": sentence_end,
                    "duration": sentence_end - sentence_start
                })
        
        self.logger.info(
            f"Extracted {len(sentence_timings)} sentence timings "
            f"from {len(word_timings)} words"
        )
        
        return sentence_timings
    
    def _split_sentence_to_words(self, sentence: str) -> List[str]:
        """
        æ–‡ã‚’å˜èªã«åˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        
        ã‚ˆã‚Šæ­£ç¢ºã«ã¯å½¢æ…‹ç´ è§£æã‚’ä½¿ç”¨ã™ã¹ãã ãŒã€
        ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ç©ºç™½ã¨å¥èª­ç‚¹ã§åˆ†å‰²
        
        Args:
            sentence: å…¥åŠ›æ–‡
            
        Returns:
            å˜èªã®ãƒªã‚¹ãƒˆ
        """
        # å¥èª­ç‚¹ã‚’é™¤å»ã—ã¦ç©ºç™½ã§åˆ†å‰²
        import re
        # å¥èª­ç‚¹ã‚’ç©ºç™½ã«ç½®æ›
        text = re.sub(r'[ã€‚ã€ï¼Œï¼ï¼Ÿ]', ' ', sentence)
        # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
        text = re.sub(r'\s+', ' ', text)
        words = [w.strip() for w in text.split() if w.strip()]
        return words


def align_text_with_whisper_timings(
    original_text: str,
    recognized_text: str,
    word_timings: List[Dict[str, Any]],
    logger: Optional[logging.Logger] = None
) -> List[Dict[str, Any]]:
    """
    å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨Whisperã®èªè­˜çµæœã‚’ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ

    DTWãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯é«˜ç²¾åº¦ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€
    ãã†ã§ãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ–‡å­—æ•°æ¯”ç‡ï¼‰

    Args:
        original_text: å…ƒã®narration textï¼ˆæ­£ç¢ºãªå›ºæœ‰åè©ã‚’å«ã‚€ï¼‰
        recognized_text: WhisperãŒèªè­˜ã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆèª¤èªè­˜ã‚ã‚Šï¼‰
        word_timings: Whisperã‹ã‚‰å–å¾—ã—ãŸå˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
        logger: ãƒ­ã‚¬ãƒ¼

    Returns:
        å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
    """
    if logger:
        logger.info(
            f"Aligning texts: original={len(original_text)} chars, "
            f"recognized={len(recognized_text)} chars"
        )

    # ğŸ”¥ DTWãŒåˆ©ç”¨å¯èƒ½ãªã‚‰DTWã‚’ä½¿ç”¨
    try:
        from src.utils.dtw_aligner import create_dtw_aligner

        dtw_aligner = create_dtw_aligner(
            logger=logger,
            debug_mode=True,  # æœ€åˆã¯ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹
            output_dir=None   # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®debug/dtwã‚’ä½¿ç”¨
        )

        if dtw_aligner:
            if logger:
                logger.info("Using DTW for high-precision alignment")

            aligned_timings = dtw_aligner.align(
                original_text=original_text,
                recognized_text=recognized_text,
                word_timings=word_timings
            )

            if logger:
                logger.info("âœ“ DTW alignment successful")
            return aligned_timings
        else:
            if logger:
                logger.warning("DTW not available, falling back to ratio-based alignment")

    except ImportError as e:
        if logger:
            logger.warning(f"DTW import failed: {e}, using fallback alignment")
    except Exception as e:
        if logger:
            logger.error(f"DTW alignment failed: {e}, using fallback alignment")

    # ğŸ”¥ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®æ–‡å­—æ•°æ¯”ç‡æ–¹å¼
    if logger:
        logger.info("Using ratio-based alignment (fallback)")

    # ç©ºç™½ã¨å¥èª­ç‚¹ã‚’é™¤å»ã—ã¦æ¯”è¼ƒç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
    import re
    def normalize_text(text: str) -> str:
        """æ¯”è¼ƒç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–"""
        # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«
        text = text.translate(str.maketrans(
            'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š',
            '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
        ))
        # ç©ºç™½ã€å¥èª­ç‚¹ã€è¨˜å·ã‚’é™¤å»
        text = re.sub(r'[\sã€ã€‚ï¼Œï¼ï¼ï¼Ÿ!?ã€Œã€ã€ã€ã€ã€‘ï¼ˆï¼‰()ã€ˆã€‰ã€Šã€‹]', '', text)
        return text

    original_normalized = normalize_text(original_text)
    recognized_normalized = normalize_text(recognized_text)

    # Whisperã®èªè­˜çµæœã‹ã‚‰æ–‡å­—ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    recognized_chars = []
    for word_info in word_timings:
        word = word_info.get("word", "").strip()
        word_normalized = normalize_text(word)
        for char in word_normalized:
            recognized_chars.append({
                "char": char,
                "start": word_info.get("start", 0.0),
                "end": word_info.get("end", 0.0),
                "probability": word_info.get("probability", 1.0)
            })

    if logger:
        logger.info(
            f"Recognized chars: {len(recognized_chars)}, "
            f"normalized: '{recognized_normalized[:50]}...'"
        )

    # ç°¡æ˜“çš„ãªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼šæ–‡å­—æ•°æ¯”ç‡ã§ãƒãƒƒãƒ”ãƒ³ã‚°
    # ã‚ˆã‚Šé«˜åº¦ãªå®Ÿè£…ã§ã¯ç·¨é›†è·é›¢ï¼ˆLevenshteinè·é›¢ï¼‰ã‚’ä½¿ç”¨å¯èƒ½
    aligned_timings = []

    if len(recognized_chars) == 0:
        # èªè­˜çµæœãŒç©ºã®å ´åˆã€å‡ç­‰ã«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å‰²ã‚Šå½“ã¦
        if logger:
            logger.warning("No recognized characters, using uniform timing")
        duration_per_char = 0.15  # 1æ–‡å­—ã‚ãŸã‚Š0.15ç§’ã¨ä»®å®š
        for i, char in enumerate(original_text):
            # å¥èª­ç‚¹ã‚‚å«ã‚€å…¨ã¦ã®æ–‡å­—ã‚’å‡¦ç†
            aligned_timings.append({
                "word": char,
                "start": i * duration_per_char,
                "end": (i + 1) * duration_per_char,
                "probability": 0.5
            })
    else:
        # æ–‡å­—æ•°æ¯”ç‡ã§ãƒãƒƒãƒ”ãƒ³ã‚°
        # å¥èª­ç‚¹ã‚’é™¤å¤–ã—ãŸæ–‡å­—ã®ã¿ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
        original_chars = [c for c in original_text if normalize_text(c)]
        ratio = len(recognized_chars) / max(len(original_chars), 1)

        if logger:
            logger.info(
                f"Alignment ratio: {ratio:.2f} "
                f"({len(recognized_chars)} recognized / {len(original_chars)} original)"
            )

        # å¥èª­ç‚¹ã‚’é™¤å¤–ã—ãŸæ–‡å­—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        normalized_char_count = 0
        last_timing = None

        for i, char in enumerate(original_text):
            if not normalize_text(char):
                # å¥èª­ç‚¹ãƒ»ç©ºç™½ã®å ´åˆ
                # ç›´å‰ã®æ–‡å­—ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ï¼ˆéŸ³å£°ã«ã¯å«ã¾ã‚Œãªã„ãŒè¡¨ç¤ºç”¨ã«å¿…è¦ï¼‰
                if last_timing:
                    # ç›´å‰ã®æ–‡å­—ã®çµ‚äº†æ™‚åˆ»ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆç¬é–“è¡¨ç¤ºï¼‰
                    aligned_timings.append({
                        "word": char,
                        "start": last_timing["end"],
                        "end": last_timing["end"],
                        "probability": last_timing.get("probability", 0.5)
                    })
                else:
                    # æœ€åˆã®æ–‡å­—ãŒå¥èª­ç‚¹ã®å ´åˆï¼ˆç¨€ï¼‰
                    aligned_timings.append({
                        "word": char,
                        "start": 0.0,
                        "end": 0.0,
                        "probability": 0.5
                    })
                continue

            # é€šå¸¸ã®æ–‡å­—ã®å ´åˆ
            # å¯¾å¿œã™ã‚‹èªè­˜æ–‡å­—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
            recognized_idx = int(normalized_char_count * ratio)
            recognized_idx = min(recognized_idx, len(recognized_chars) - 1)

            if recognized_idx < len(recognized_chars):
                timing = recognized_chars[recognized_idx]
                aligned_timings.append({
                    "word": char,
                    "start": timing["start"],
                    "end": timing["end"],
                    "probability": timing["probability"]
                })
                last_timing = timing
            else:
                # ç¯„å›²å¤–ã®å ´åˆã€æœ€å¾Œã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨
                last_timing = recognized_chars[-1]
                aligned_timings.append({
                    "word": char,
                    "start": last_timing["end"],
                    "end": last_timing["end"] + 0.15,
                    "probability": 0.5
                })

            normalized_char_count += 1

    if logger:
        logger.info(
            f"âœ“ Aligned {len(aligned_timings)} characters from original text "
            f"to Whisper timings"
        )

    return aligned_timings


def create_whisper_extractor(
    model_name: str = "base",
    logger: Optional[logging.Logger] = None,
    language: str = "ja",
    use_stable_ts: bool = True,
    suppress_silence: bool = True,
    vad: bool = True,
    vad_threshold: float = 0.35
) -> Optional[WhisperTimingExtractor]:
    """
    WhisperTimingExtractorã‚’ä½œæˆ

    Args:
        model_name: Whisperãƒ¢ãƒ‡ãƒ«å
        logger: ãƒ­ã‚¬ãƒ¼
        language: è¨€èªã‚³ãƒ¼ãƒ‰
        use_stable_ts: stable-tsã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆç„¡éŸ³æŠ‘åˆ¶ã€ã‚®ãƒ£ãƒƒãƒ—èª¿æ•´ãŒæœ‰åŠ¹ï¼‰
        suppress_silence: ç„¡éŸ³åŒºé–“ã‚’æŠ‘åˆ¶ã™ã‚‹ã‹ï¼ˆstable-tsä½¿ç”¨æ™‚ã®ã¿ï¼‰
        vad: Voice Activity Detectionã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆstable-tsä½¿ç”¨æ™‚ã®ã¿ï¼‰
        vad_threshold: VADã®é–¾å€¤ï¼ˆ0-1ã€ä½ã„ã»ã©å³æ ¼ï¼‰

    Returns:
        WhisperTimingExtractorï¼ˆåˆ©ç”¨ä¸å¯ã®å ´åˆã¯Noneï¼‰
    """
    if not WHISPER_AVAILABLE:
        if logger:
            logger.warning(
                "Whisper not available. Install with: pip install openai-whisper"
            )
        return None

    try:
        return WhisperTimingExtractor(
            model_name=model_name,
            logger=logger,
            language=language,
            use_stable_ts=use_stable_ts,
            suppress_silence=suppress_silence,
            vad=vad,
            vad_threshold=vad_threshold
        )
    except Exception as e:
        if logger:
            logger.error(f"Failed to create Whisper extractor: {e}")
        return None

