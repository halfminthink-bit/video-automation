"""
Whisperã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import tempfile

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    whisper = None


class WhisperTimingExtractor:
    """Whisperã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—"""
    
    def __init__(
        self,
        model_name: str = "base",
        logger: Optional[logging.Logger] = None,
        language: str = "ja"
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            model_name: Whisperãƒ¢ãƒ‡ãƒ«åï¼ˆtiny, base, small, medium, largeï¼‰
            logger: ãƒ­ã‚¬ãƒ¼
            language: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ"ja" = æ—¥æœ¬èªï¼‰
        """
        if not WHISPER_AVAILABLE:
            raise ImportError(
                "whisper package is required. "
                "Install with: pip install openai-whisper"
            )
        
        self.logger = logger or logging.getLogger(__name__)
        self.language = language
        
        self.logger.info(f"Loading Whisper model: {model_name}")
        try:
            # CPUã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯FP32ã‚’ä½¿ç”¨ï¼ˆFP16ã¯GPUã®ã¿å¯¾å¿œï¼‰
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model = whisper.load_model(model_name, device=device)
            self.logger.info(f"Whisper model loaded successfully on {device}")
        except Exception as e:
            self.logger.error(f"Failed to load Whisper model: {e}")
            raise
    
    def extract_word_timings(
        self,
        audio_path: Path,
        text: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        éŸ³å£°ã‹ã‚‰å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            text: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
            
        Returns:
            å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ:
            [
                {
                    "word": "ç¹”ç”°",
                    "start": 0.5,
                    "end": 0.8,
                    "probability": 0.95
                },
                ...
            ]
        """
        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        self.logger.info(f"Extracting word timings from: {audio_path}")
        
        try:
            # Whisperã§éŸ³å£°èªè­˜ï¼ˆword_timestamps=Trueã§å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—ï¼‰
            # CPUã§ã¯FP16ãŒä½¿ãˆãªã„ãŸã‚ã€fp16=Falseã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
            import torch
            fp16_enabled = torch.cuda.is_available()

            result = self.model.transcribe(
                str(audio_path),
                language=self.language,
                word_timestamps=True,
                # initial_promptã¯ä½¿ç”¨ã—ãªã„ï¼ˆå…¨æ–‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ãŸã‚ï¼‰
                # Whisperã®ä»•æ§˜: initial_promptã¯ã€Œç›´å‰ã«è©±ã•ã‚ŒãŸå†…å®¹ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã€
                # æ¸¡ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œã‚‚ã†è©±ã—çµ‚ã‚ã£ãŸã€ã¨åˆ¤æ–­ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
                fp16=fp16_enabled,
                # èªè­˜ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                condition_on_previous_text=False,
                no_speech_threshold=0.3,
                logprob_threshold=-1.0,
                compression_ratio_threshold=2.4,
                temperature=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],
                beam_size=5,
                patience=1.0,
                length_penalty=1.0,
                suppress_tokens="-1",
                task="transcribe"
            )

            # ãƒ‡ãƒãƒƒã‚°: Whisperã®èªè­˜çµæœã‚’ç¢ºèª
            self.logger.info(f"Whisper recognized text: {result.get('text', '')}")
            segments = result.get("segments", [])
            self.logger.info(f"Number of segments: {len(segments)}")
            for i, seg in enumerate(segments):
                segment_text = seg.get("text", "")
                words = seg.get("words", []) or []
                no_speech_prob = seg.get("no_speech_prob", 0)
                self.logger.info(
                    f"  Segment {i}: {segment_text} "
                    f"({len(words)} words, no_speech_prob={no_speech_prob:.3f})"
                )
            
            # å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’æŠ½å‡º
            word_timings = []
            for segment in result.get("segments", []):
                for word_info in segment.get("words", []):
                    word_timings.append({
                        "word": word_info.get("word", "").strip(),
                        "start": word_info.get("start", 0.0),
                        "end": word_info.get("end", 0.0),
                        "probability": word_info.get("probability", 1.0)
                    })

            self.logger.info(
                f"Extracted {len(word_timings)} word timings from Whisper "
                f"(duration: {result.get('segments', [{}])[-1].get('end', 0):.1f}s)"
            )

            # ğŸ”¥ æ–°æ©Ÿèƒ½ï¼šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œ
            if text:
                self.logger.info("Aligning Whisper timings with original text...")
                recognized_text = result.get('text', '')
                aligned_timings = align_text_with_whisper_timings(
                    original_text=text,
                    recognized_text=recognized_text,
                    word_timings=word_timings,
                    logger=self.logger
                )
                self.logger.info(
                    f"âœ“ Alignment complete: {len(aligned_timings)} characters mapped"
                )
                return aligned_timings
            else:
                # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆã¯ã€Whisperã®èªè­˜çµæœã‚’ãã®ã¾ã¾è¿”ã™
                return word_timings
            
        except Exception as e:
            self.logger.error(f"Failed to extract word timings: {e}", exc_info=True)
            raise
    
    def extract_sentence_timings(
        self,
        audio_path: Path,
        sentences: List[str],
        word_timings: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ–‡ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
        
        å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‹ã‚‰ã€å„æ–‡ã®é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            sentences: æ–‡ã®ãƒªã‚¹ãƒˆ
            word_timings: äº‹å‰ã«å–å¾—ã—ãŸå˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ï¼ˆNoneã®å ´åˆã¯å–å¾—ï¼‰
            
        Returns:
            æ–‡ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ:
            [
                {
                    "sentence": "ç¹”ç”°ä¿¡é•·ã¯...",
                    "start": 0.5,
                    "end": 3.2
                },
                ...
            ]
        """
        if word_timings is None:
            # å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
            word_timings = self.extract_word_timings(audio_path)
        
        if not word_timings:
            self.logger.warning("No word timings available, returning empty list")
            return []
        
        # å„æ–‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç®—
        sentence_timings = []
        current_word_idx = 0
        total_words = len(word_timings)
        
        for sentence_idx, sentence in enumerate(sentences):
            if not sentence.strip():
                continue
            
            # æ–‡ã®æ–‡å­—æ•°ã‚’è¨ˆç®—ï¼ˆæ—¥æœ¬èªã®å ´åˆã€æ–‡å­—æ•°ã§å¤§ä½“ã®é•·ã•ã‚’æ¨å®šï¼‰
            sentence_length = len(sentence)
            
            # ã“ã®æ–‡ã«å¯¾å¿œã™ã‚‹å˜èªæ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼šæ–‡å­—æ•°ã®æ¯”ç‡ï¼‰
            # å®Ÿéš›ã®éŸ³å£°èªè­˜çµæœã¨å°æœ¬ã®æ–‡å­—æ•°ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
            # ç´¯ç©æ–‡å­—æ•°ã‹ã‚‰æ¨å®š
            total_sentence_chars = sum(len(s) for s in sentences)
            if total_sentence_chars > 0:
                char_ratio = sentence_length / total_sentence_chars
                estimated_words = int(total_words * char_ratio)
            else:
                estimated_words = max(1, sentence_length // 2)  # 1æ–‡å­— = 0.5å˜èªï¼ˆæ¨å®šï¼‰
            
            # é–‹å§‹ä½ç½®ã‚’æ±ºå®š
            sentence_start = None
            sentence_end = None
            
            # ç¾åœ¨ã®ä½ç½®ã‹ã‚‰é–‹å§‹ã—ã¦ã€å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—
            words_for_sentence = min(estimated_words, total_words - current_word_idx)
            
            if words_for_sentence > 0 and current_word_idx < total_words:
                # ã“ã®æ–‡ã«å¯¾å¿œã™ã‚‹å˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å–å¾—
                sentence_start = word_timings[current_word_idx]["start"]
                sentence_end = word_timings[min(
                    current_word_idx + words_for_sentence - 1,
                    total_words - 1
                )]["end"]
                
                # æ¬¡ã®æ–‡ã®é–‹å§‹ä½ç½®ã‚’æ›´æ–°
                current_word_idx += words_for_sentence
            else:
                # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å‰ã®æ–‡ã®çµ‚äº†æ™‚é–“ã‚’ä½¿ç”¨
                if sentence_timings:
                    last_end = sentence_timings[-1]["end"]
                    # æ¨å®šæ™‚é–“ã‚’è¨ˆç®—ï¼ˆæ–‡å­—æ•°ã‹ã‚‰ï¼‰
                    estimated_duration = len(sentence) * 0.15  # 1æ–‡å­— = 0.15ç§’ï¼ˆæ¨å®šï¼‰
                    sentence_start = last_end
                    sentence_end = last_end + estimated_duration
                else:
                    # æœ€åˆã®æ–‡ã§ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
                    sentence_start = 0.0
                    estimated_duration = len(sentence) * 0.15
                    sentence_end = estimated_duration
            
            if sentence_start is not None and sentence_end is not None:
                sentence_timings.append({
                    "sentence": sentence,
                    "start": sentence_start,
                    "end": sentence_end,
                    "duration": sentence_end - sentence_start
                })
        
        self.logger.info(
            f"Extracted {len(sentence_timings)} sentence timings "
            f"from {len(word_timings)} words"
        )
        
        return sentence_timings
    
    def _split_sentence_to_words(self, sentence: str) -> List[str]:
        """
        æ–‡ã‚’å˜èªã«åˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        
        ã‚ˆã‚Šæ­£ç¢ºã«ã¯å½¢æ…‹ç´ è§£æã‚’ä½¿ç”¨ã™ã¹ãã ãŒã€
        ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ç©ºç™½ã¨å¥èª­ç‚¹ã§åˆ†å‰²
        
        Args:
            sentence: å…¥åŠ›æ–‡
            
        Returns:
            å˜èªã®ãƒªã‚¹ãƒˆ
        """
        # å¥èª­ç‚¹ã‚’é™¤å»ã—ã¦ç©ºç™½ã§åˆ†å‰²
        import re
        # å¥èª­ç‚¹ã‚’ç©ºç™½ã«ç½®æ›
        text = re.sub(r'[ã€‚ã€ï¼Œï¼ï¼Ÿ]', ' ', sentence)
        # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
        text = re.sub(r'\s+', ' ', text)
        words = [w.strip() for w in text.split() if w.strip()]
        return words


def align_text_with_whisper_timings(
    original_text: str,
    recognized_text: str,
    word_timings: List[Dict[str, Any]],
    logger: Optional[logging.Logger] = None
) -> List[Dict[str, Any]]:
    """
    å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨Whisperã®èªè­˜çµæœã‚’ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã—ã€
    å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—ã«ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹

    Args:
        original_text: å…ƒã®narration textï¼ˆæ­£ç¢ºãªå›ºæœ‰åè©ã‚’å«ã‚€ï¼‰
        recognized_text: WhisperãŒèªè­˜ã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆèª¤èªè­˜ã‚ã‚Šï¼‰
        word_timings: Whisperã‹ã‚‰å–å¾—ã—ãŸå˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
        logger: ãƒ­ã‚¬ãƒ¼

    Returns:
        å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±:
        [
            {
                "word": "ä¿¡",  # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—
                "start": 0.0,
                "end": 0.24,
                "probability": 0.95
            },
            ...
        ]

    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :
    1. å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§æ¯”è¼ƒ
    2. é¡ä¼¼åº¦ã®é«˜ã„éƒ¨åˆ†ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    3. Whisperã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—ä½ç½®ã«å¯¾å¿œä»˜ã‘
    """
    if logger:
        logger.info(
            f"Aligning texts: original={len(original_text)} chars, "
            f"recognized={len(recognized_text)} chars"
        )

    # ç©ºç™½ã¨å¥èª­ç‚¹ã‚’é™¤å»ã—ã¦æ¯”è¼ƒç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
    import re
    def normalize_text(text: str) -> str:
        """æ¯”è¼ƒç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–"""
        # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«
        text = text.translate(str.maketrans(
            'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š',
            '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
        ))
        # ç©ºç™½ã€å¥èª­ç‚¹ã€è¨˜å·ã‚’é™¤å»
        text = re.sub(r'[\sã€ã€‚ï¼Œï¼ï¼ï¼Ÿ!?ã€Œã€ã€ã€ã€ã€‘ï¼ˆï¼‰()ã€ˆã€‰ã€Šã€‹]', '', text)
        return text

    original_normalized = normalize_text(original_text)
    recognized_normalized = normalize_text(recognized_text)

    # Whisperã®èªè­˜çµæœã‹ã‚‰æ–‡å­—ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    recognized_chars = []
    for word_info in word_timings:
        word = word_info.get("word", "").strip()
        word_normalized = normalize_text(word)
        for char in word_normalized:
            recognized_chars.append({
                "char": char,
                "start": word_info.get("start", 0.0),
                "end": word_info.get("end", 0.0),
                "probability": word_info.get("probability", 1.0)
            })

    if logger:
        logger.info(
            f"Recognized chars: {len(recognized_chars)}, "
            f"normalized: '{recognized_normalized[:50]}...'"
        )

    # ç°¡æ˜“çš„ãªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼šæ–‡å­—æ•°æ¯”ç‡ã§ãƒãƒƒãƒ”ãƒ³ã‚°
    # ã‚ˆã‚Šé«˜åº¦ãªå®Ÿè£…ã§ã¯ç·¨é›†è·é›¢ï¼ˆLevenshteinè·é›¢ï¼‰ã‚’ä½¿ç”¨å¯èƒ½
    aligned_timings = []

    if len(recognized_chars) == 0:
        # èªè­˜çµæœãŒç©ºã®å ´åˆã€å‡ç­‰ã«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å‰²ã‚Šå½“ã¦
        if logger:
            logger.warning("No recognized characters, using uniform timing")
        duration_per_char = 0.15  # 1æ–‡å­—ã‚ãŸã‚Š0.15ç§’ã¨ä»®å®š
        for i, char in enumerate(original_text):
            if normalize_text(char):  # ç©ºç™½ã‚„å¥èª­ç‚¹ä»¥å¤–
                aligned_timings.append({
                    "word": char,
                    "start": i * duration_per_char,
                    "end": (i + 1) * duration_per_char,
                    "probability": 0.5
                })
    else:
        # æ–‡å­—æ•°æ¯”ç‡ã§ãƒãƒƒãƒ”ãƒ³ã‚°
        original_chars = [c for c in original_text if normalize_text(c)]
        ratio = len(recognized_chars) / max(len(original_chars), 1)

        if logger:
            logger.info(
                f"Alignment ratio: {ratio:.2f} "
                f"({len(recognized_chars)} recognized / {len(original_chars)} original)"
            )

        for i, char in enumerate(original_text):
            if not normalize_text(char):
                # ç©ºç™½ã‚„å¥èª­ç‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
                continue

            # å¯¾å¿œã™ã‚‹èªè­˜æ–‡å­—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
            recognized_idx = int(i * ratio)
            recognized_idx = min(recognized_idx, len(recognized_chars) - 1)

            if recognized_idx < len(recognized_chars):
                timing = recognized_chars[recognized_idx]
                aligned_timings.append({
                    "word": char,
                    "start": timing["start"],
                    "end": timing["end"],
                    "probability": timing["probability"]
                })
            else:
                # ç¯„å›²å¤–ã®å ´åˆã€æœ€å¾Œã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨
                last_timing = recognized_chars[-1]
                aligned_timings.append({
                    "word": char,
                    "start": last_timing["end"],
                    "end": last_timing["end"] + 0.15,
                    "probability": 0.5
                })

    if logger:
        logger.info(
            f"âœ“ Aligned {len(aligned_timings)} characters from original text "
            f"to Whisper timings"
        )

    return aligned_timings


def create_whisper_extractor(
    model_name: str = "base",
    logger: Optional[logging.Logger] = None,
    language: str = "ja"
) -> Optional[WhisperTimingExtractor]:
    """
    WhisperTimingExtractorã‚’ä½œæˆ

    Args:
        model_name: Whisperãƒ¢ãƒ‡ãƒ«å
        logger: ãƒ­ã‚¬ãƒ¼
        language: è¨€èªã‚³ãƒ¼ãƒ‰

    Returns:
        WhisperTimingExtractorï¼ˆåˆ©ç”¨ä¸å¯ã®å ´åˆã¯Noneï¼‰
    """
    if not WHISPER_AVAILABLE:
        if logger:
            logger.warning(
                "Whisper not available. Install with: pip install openai-whisper"
            )
        return None

    try:
        return WhisperTimingExtractor(
            model_name=model_name,
            logger=logger,
            language=language
        )
    except Exception as e:
        if logger:
            logger.error(f"Failed to create Whisper extractor: {e}")
        return None

