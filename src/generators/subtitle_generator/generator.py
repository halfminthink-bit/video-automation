"""
å­—å¹•ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯

å…¨ä½“ãƒ•ãƒ­ãƒ¼ã®åˆ¶å¾¡ã€å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã‚’è¡Œã†ã€‚
"""

from typing import List, Dict, Any, Optional, Tuple
import logging

from src.core.models import SubtitleEntry
from src.utils.whisper_timing import create_whisper_extractor
from .text_splitter import TextSplitter
from .timing_processor import TimingProcessor
from .formatter import SubtitleFormatter


class SubtitleGenerator:
    """
    å­—å¹•ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰

    è²¬ä»»:
    - å…¨ä½“ãƒ•ãƒ­ãƒ¼ã®åˆ¶å¾¡
    - TextSplitter, TimingProcessor, SubtitleFormatter ã®çµ„ã¿åˆã‚ã›
    - audio_timing.json ã‹ã‚‰ã®å­—å¹•ç”Ÿæˆ

    å¤‰æ›´é »åº¦: ä½ï¼ˆãƒ•ãƒ­ãƒ¼ã®å¤‰æ›´æ™‚ã®ã¿ï¼‰
    """

    def __init__(
        self,
        config: Dict[str, Any],
        logger: Optional[logging.Logger] = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            config: å­—å¹•ç”Ÿæˆè¨­å®š
            logger: ãƒ­ã‚¬ãƒ¼
        """
        self.config = config
        self.logger = logger or logging.getLogger(__name__)

        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.splitter = TextSplitter(config, logger=logger)
        self.timing = TimingProcessor(config, logger=logger)
        self.formatter = SubtitleFormatter(config, logger=logger)

        # è¨­å®šå€¤ã®å–å¾—ï¼ˆäº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
        self.max_lines = max(1, config.get("max_lines", 2))
        self.max_chars_per_line = config.get("max_chars_per_line", 20)

        timing_config = config.get("timing", {})
        self.min_display_duration = timing_config.get("min_display_duration", 4.0)
        self.max_display_duration = timing_config.get("max_display_duration", 6.0)
        self.lead_time = timing_config.get("lead_time", 0.2)
        self.subtitle_gap = timing_config.get("subtitle_gap", 0.1)
        self.prevent_overlap = timing_config.get("prevent_overlap", True)
        self.overlap_priority = timing_config.get("overlap_priority", "next_subtitle")

        morphological = config.get("morphological_analysis", {})
        self.use_mecab = morphological.get("use_mecab", False)
        self.break_on = morphological.get("break_on", ["ã€‚", "ã€", "ï¼", "ï¼Ÿ"])

        # åˆ†å‰²æˆ¦ç•¥ã®è¨­å®šï¼ˆäº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
        splitting = config.get("splitting", {})
        self.window_size = splitting.get("window_size", 3)
        self.priority_scores = splitting.get("priority_scores", {
            "punctuation": 120,
            "morpheme_boundary": 150,
            "particle": 100,
            "hiragana_to_kanji": 80,
            "kanji_to_hiragana": 60,
            "katakana_boundary": 40
        })
        self.penalties = splitting.get("penalties", {
            "distance_from_ideal": 5,
            "ends_with_n_tsu": 20,
            "splits_number": 50,
            "splits_alphabet": 50,
            "splits_verb_adjective": 500
        })
        self.particles = splitting.get("particles", [
            "ã¯", "ãŒ", "ã‚’", "ã«", "ã§", "ã¨", "ã‚‚", "ã‚„", "ã‹ã‚‰", "ã¾ã§", "ã‚ˆã‚Š"
        ])
        self.balance_lines = splitting.get("balance_lines", True)
        self.min_line_length = splitting.get("min_line_length", 3)

        # å¥èª­ç‚¹è¡¨ç¤ºè¨­å®š
        self.remove_punctuation = config.get("remove_punctuation_in_display", False)

        # MeCabã®åˆæœŸåŒ–ï¼ˆä½¿ç”¨ã™ã‚‹å ´åˆï¼‰
        self.mecab = None
        if self.use_mecab:
            self._init_mecab()

        # Whisperã®è¨­å®šï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±å–å¾—ç”¨ï¼‰
        whisper_config = config.get("whisper", {})
        self.use_whisper = whisper_config.get("enabled", True)
        self.whisper_model = whisper_config.get("model", "base")
        self.whisper_extractor = None
        if self.use_whisper:
            self.whisper_extractor = create_whisper_extractor(
                model_name=self.whisper_model,
                logger=self.logger,
                language="ja"
            )
            if self.whisper_extractor is None:
                self.logger.warning(
                    "Whisper is enabled but not available. "
                    "Falling back to character-based timing."
                )
                self.use_whisper = False
    

    def _is_hiragana(self, char: str) -> bool:
        """ã²ã‚‰ãŒãªã‹ã©ã†ã‹åˆ¤å®š"""
        return '\u3040' <= char <= '\u309F'

    def _is_katakana(self, char: str) -> bool:
        """ã‚«ã‚¿ã‚«ãƒŠã‹ã©ã†ã‹åˆ¤å®š"""
        return '\u30A0' <= char <= '\u30FF'

    def _is_kanji(self, char: str) -> bool:
        """æ¼¢å­—ã‹ã©ã†ã‹åˆ¤å®š"""
        return '\u4E00' <= char <= '\u9FFF'

    def _is_number(self, char: str) -> bool:
        """æ•°å­—ã‹ã©ã†ã‹åˆ¤å®š"""
        return char.isdigit() or '\uFF10' <= char <= '\uFF19'

    def _is_alphabet(self, char: str) -> bool:
        """è‹±å­—ã‹ã©ã†ã‹åˆ¤å®š"""
        return char.isalpha() and ord(char) < 128

    def _find_punctuation_positions_from_characters(
        self,
        characters: List[str]
    ) -> Dict[int, str]:
        """
        charactersã‹ã‚‰ç›´æ¥å¥èª­ç‚¹ä½ç½®ã‚’æ¤œå‡º

        ä¿®æ­£å¾Œã®whisper_timing.pyã§ã¯ã€charactersã«å¥èª­ç‚¹ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸãŸã‚ã€
        ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

        Args:
            characters: æ–‡å­—é…åˆ—ï¼ˆå¥èª­ç‚¹ã‚’å«ã‚€ï¼‰

        Returns:
            {ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: å¥èª­ç‚¹, ...}  # charactersã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ â†’ å¥èª­ç‚¹
            ä¾‹: {4: "ã€", 24: "ã€‚", ...}
        """
        punctuation_marks = set(["ã€‚", "ã€", "ï¼", "ï¼Ÿ", "â€¦"])
        positions = {}

        for i, char in enumerate(characters):
            if char in punctuation_marks:
                positions[i] = char

        return positions

    def _detect_morpheme_boundaries(
        self,
        characters: List[str]
    ) -> Dict[str, Any]:
        """
        MeCabã‚’ä½¿ã£ã¦å½¢æ…‹ç´ å¢ƒç•Œã‚’æ¤œå‡º

        Returns:
            {
                'boundaries': [3, 7, 12, ...],  # å½¢æ…‹ç´ ã®å¢ƒç•Œä½ç½®
                'morphemes': [
                    {'surface': 'æˆ¦å›½', 'pos': 'åè©', 'start': 0, 'end': 2},
                    {'surface': 'æ™‚ä»£', 'pos': 'åè©', 'start': 2, 'end': 4},
                    ...
                ],
                'verb_adjective_positions': set([5, 6, 7, ...])  # å‹•è©ãƒ»å½¢å®¹è©ã®å†…éƒ¨ä½ç½®
            }
        """
        if not self.use_mecab or self.mecab is None:
            # MeCabãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ç©ºã®çµæœã‚’è¿”ã™
            return {
                'boundaries': [],
                'morphemes': [],
                'verb_adjective_positions': set()
            }

        try:
            text = "".join(characters)

            # MeCabã§è§£æ
            node = self.mecab.parseToNode(text)

            morphemes = []
            boundaries = []
            verb_adjective_positions = set()
            current_pos = 0

            while node:
                surface = node.surface
                features = node.feature.split(',')
                pos = features[0] if features else "æœªçŸ¥èª"

                if surface:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆ
                    morpheme_len = len(surface)
                    morpheme_end = current_pos + morpheme_len

                    morphemes.append({
                        'surface': surface,
                        'pos': pos,
                        'start': current_pos,
                        'end': morpheme_end
                    })

                    # å½¢æ…‹ç´ ã®çµ‚ã‚ã‚Šä½ç½®ã‚’å¢ƒç•Œã¨ã—ã¦è¨˜éŒ²
                    if morpheme_end < len(characters):
                        boundaries.append(morpheme_end)

                    # å‹•è©ãƒ»å½¢å®¹è©ã®å†…éƒ¨ä½ç½®ã‚’è¨˜éŒ²ï¼ˆå¢ƒç•Œä»¥å¤–ã®ä½ç½®ï¼‰
                    if pos in ['å‹•è©', 'å½¢å®¹è©']:
                        for i in range(current_pos + 1, morpheme_end):
                            verb_adjective_positions.add(i)

                    current_pos = morpheme_end

                node = node.next

            self.logger.debug(
                f"MeCab detected {len(morphemes)} morphemes, "
                f"{len(boundaries)} boundaries, "
                f"{len(verb_adjective_positions)} verb/adj internal positions"
            )

            return {
                'boundaries': boundaries,
                'morphemes': morphemes,
                'verb_adjective_positions': verb_adjective_positions
            }

        except Exception as e:
            self.logger.warning(f"MeCab analysis failed: {e}")
            return {
                'boundaries': [],
                'morphemes': [],
                'verb_adjective_positions': set()
            }

    def _find_split_position_with_score(
        self,
        text: str,
        characters: List[str],
        max_chars: int,
        punctuation_positions: Dict[int, str],
        boundaries: Dict[str, List[int]],
        morpheme_info: Optional[Dict[str, Any]] = None
    ) -> tuple[int, str]:
        """
        æœ€é©ãªåˆ†å‰²ä½ç½®ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹å¼ã§æ±ºå®š

        å„ªå…ˆé †ä½:
        1. å¥èª­ç‚¹ï¼ˆã‚¹ã‚³ã‚¢: 120ï¼‰
        2. å½¢æ…‹ç´ å¢ƒç•Œï¼ˆã‚¹ã‚³ã‚¢: 150ï¼‰ â† NEW
        3. åŠ©è©ã®å¾Œï¼ˆã‚¹ã‚³ã‚¢: 100ï¼‰
        4. ã²ã‚‰ãŒãªâ†’æ¼¢å­—ï¼ˆã‚¹ã‚³ã‚¢: 80ï¼‰
        5. æ¼¢å­—â†’ã²ã‚‰ãŒãªï¼ˆã‚¹ã‚³ã‚¢: 60ï¼‰
        6. ã‚«ã‚¿ã‚«ãƒŠå¢ƒç•Œï¼ˆã‚¹ã‚³ã‚¢: 40ï¼‰

        ãƒšãƒŠãƒ«ãƒ†ã‚£:
        - ç†æƒ³ä½ç½®ã‹ã‚‰é›¢ã‚Œã‚‹ã”ã¨ã« -5ç‚¹/æ–‡å­—
        - ã€Œã‚“ã€ã€Œã£ã€ã§çµ‚ã‚ã‚‹: -20ç‚¹
        - æ•°å­—ãƒ»è‹±å­—ã‚’åˆ†å‰²: -50ç‚¹
        - åˆ†å‰²å¾Œã®æ–­ç‰‡ãŒçŸ­ã™ãã‚‹: -200ç‚¹
        - åˆ†å‰²ãƒãƒ©ãƒ³ã‚¹ãŒæ‚ªã„: æœ€å¤§-50ç‚¹
        - å‹•è©ãƒ»å½¢å®¹è©ã®é€”ä¸­ã§åˆ†å‰²: -500ç‚¹ â† NEW

        Returns:
            (åˆ†å‰²ä½ç½®, åˆ†å‰²ç†ç”±)
        """
        if len(characters) <= max_chars:
            return (len(characters), "no_split_needed")

        # æœ€å°æ–­ç‰‡é•·ï¼ˆã“ã‚Œã‚ˆã‚ŠçŸ­ã„æ–­ç‰‡ã‚’ä½œã‚‰ãªã„ï¼‰
        MIN_CHUNK_LENGTH = 10

        # ç†æƒ³ä½ç½®ï¼ˆmax_charsã«è¿‘ã„ä½ç½®ï¼‰
        ideal_pos = max_chars

        # æ¢ç´¢ç¯„å›²
        search_start = max(1, ideal_pos - self.window_size)
        search_end = min(len(characters), ideal_pos + self.window_size + 1)

        best_score = -99999
        best_pos = ideal_pos
        best_reason = "forced"

        # å½¢æ…‹ç´ æƒ…å ±ã®å–å¾—
        morpheme_boundaries = []
        verb_adjective_positions = set()
        if morpheme_info:
            morpheme_boundaries = morpheme_info.get('boundaries', [])
            verb_adjective_positions = morpheme_info.get('verb_adjective_positions', set())

        for pos in range(search_start, search_end):
            score = 0
            reason = ""

            # åˆ†å‰²å¾Œã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
            first_part_len = pos
            second_part_len = len(characters) - pos

            # æœ€å°é•·ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæ–­ç‰‡ãŒçŸ­ã™ãã‚‹å ´åˆã¯å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
            if first_part_len < MIN_CHUNK_LENGTH:
                score -= 200
            if second_part_len < MIN_CHUNK_LENGTH:
                score -= 200

            # ãƒãƒ©ãƒ³ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆãªã‚‹ã¹ãå‡ç­‰ã«åˆ†å‰²ï¼‰
            # ç†æƒ³æ¯”ç‡ã¯50:50ã€ãã“ã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©ãƒšãƒŠãƒ«ãƒ†ã‚£
            ideal_ratio = 0.5
            actual_ratio = first_part_len / len(characters)
            balance_penalty = abs(ideal_ratio - actual_ratio) * 100
            score -= balance_penalty

            # å¥èª­ç‚¹ã®å‡¦ç†
            # ã€Œã€ã€ã®å ´åˆã¯ç›´å¾Œã§åˆ†å‰²ï¼ˆã€Œã€ã€ã‚’å«ã‚ã‚‹ï¼‰
            # ã€Œã€‚ã€ã€Œï¼ã€ã€Œï¼Ÿã€ã®å ´åˆã¯ç›´å¾Œã§åˆ†å‰²ï¼ˆã“ã‚Œã‚‰ã‚‚å«ã‚ã‚‹ï¼‰
            if pos > 0 and (pos - 1) in punctuation_positions:
                punct = punctuation_positions[pos - 1]
                if punct == "ã€":
                    # ã€Œã€ã€ã®ç›´å¾Œã§åˆ†å‰²
                    score += self.priority_scores.get("punctuation", 120)
                    reason = "punctuation_after_comma"

            # ãã®ä»–ã®å¥èª­ç‚¹ï¼ˆã€Œã€‚ã€ãªã©ï¼‰ã‚‚ç›´å¾Œã§åˆ†å‰²
            if pos in punctuation_positions:
                punct = punctuation_positions[pos]
                if punct in ["ã€‚", "ï¼", "ï¼Ÿ", "â€¦"]:
                    score += self.priority_scores.get("punctuation", 120)
                    reason = f"punctuation_{punct}"

            # å½¢æ…‹ç´ å¢ƒç•Œï¼ˆå¥èª­ç‚¹ã®æ¬¡ã«å„ªå…ˆï¼‰
            if pos in morpheme_boundaries:
                score += self.priority_scores.get("morpheme_boundary", 150)
                if not reason:  # å¥èª­ç‚¹ãŒãªã„å ´åˆã®ã¿ç†ç”±ã‚’è¨­å®š
                    reason = "morpheme_boundary"

            # åŠ©è©ã®å¾Œ
            if pos in boundaries.get("particles", []):
                score += self.priority_scores.get("particle", 100)
                if not reason:
                    reason = "particle"

            # ã²ã‚‰ãŒãªâ†’æ¼¢å­—
            elif pos in boundaries.get("hiragana_to_kanji", []):
                score += self.priority_scores.get("hiragana_to_kanji", 80)
                if not reason:
                    reason = "hiragana_to_kanji"

            # æ¼¢å­—â†’ã²ã‚‰ãŒãª
            elif pos in boundaries.get("kanji_to_hiragana", []):
                score += self.priority_scores.get("kanji_to_hiragana", 60)
                if not reason:
                    reason = "kanji_to_hiragana"

            # ã‚«ã‚¿ã‚«ãƒŠå¢ƒç•Œ
            elif pos in boundaries.get("katakana_boundary", []):
                score += self.priority_scores.get("katakana_boundary", 40)
                if not reason:
                    reason = "katakana_boundary"

            # å‹•è©ãƒ»å½¢å®¹è©ã®é€”ä¸­ã§åˆ†å‰²ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
            if pos in verb_adjective_positions:
                score -= self.penalties.get("splits_verb_adjective", 500)
                self.logger.debug(f"Position {pos} splits verb/adjective, penalty applied")

            # è·é›¢ãƒšãƒŠãƒ«ãƒ†ã‚£
            distance = abs(pos - ideal_pos)
            score -= distance * self.penalties.get("distance_from_ideal", 5)

            # ã€Œã‚“ã€ã€Œã£ã€ã§çµ‚ã‚ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
            if pos > 0 and characters[pos - 1] in ["ã‚“", "ã£"]:
                score -= self.penalties.get("ends_with_n_tsu", 20)

            # æ•°å­—ã‚’åˆ†å‰²ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
            if pos > 0 and pos < len(characters):
                if self._is_number(characters[pos - 1]) and self._is_number(characters[pos]):
                    score -= self.penalties.get("splits_number", 50)

            # è‹±å­—ã‚’åˆ†å‰²ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
            if pos > 0 and pos < len(characters):
                if self._is_alphabet(characters[pos - 1]) and self._is_alphabet(characters[pos]):
                    score -= self.penalties.get("splits_alphabet", 50)

            if score > best_score:
                best_score = score
                best_pos = pos
                best_reason = reason if reason else "best_available"

        # ã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹å ´åˆã¯å¼·åˆ¶åˆ†å‰²
        if best_score < -100:
            best_pos = ideal_pos
            best_reason = "forced"

        return (best_pos, best_reason)

    def _split_into_balanced_lines(
        self,
        text: str,
        characters: List[str],
        max_chars_per_line: int,
        max_lines: int,
        punctuation_positions: Dict[int, str],
        boundaries: Dict[str, List[int]]
    ) -> List[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’è¤‡æ•°è¡Œã«åˆ†å‰²ï¼ˆãªã‚‹ã¹ãå‡ç­‰ã«ï¼‰

        Args:
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¥èª­ç‚¹ã‚ã‚Šï¼‰
            characters: æ–‡å­—é…åˆ—ï¼ˆå¥èª­ç‚¹ãªã—ï¼‰
            max_chars_per_line: 1è¡Œã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°
            max_lines: æœ€å¤§è¡Œæ•°
            punctuation_positions: å¥èª­ç‚¹ä½ç½®ã®ãƒãƒƒãƒ—
            boundaries: æ–‡å­—ç¨®å¢ƒç•Œã®ãƒãƒƒãƒ—

        Returns:
            è¡Œã®ãƒªã‚¹ãƒˆï¼ˆå¥èª­ç‚¹ã‚’é™¤å»æ¸ˆã¿ï¼‰
        """
        if len(characters) <= max_chars_per_line:
            return ["".join(characters)]

        # 36æ–‡å­—ä»¥å†…ï¼ˆmax_chars_per_line * max_linesï¼‰ã®å ´åˆã€æ®µéšçš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if len(characters) <= max_chars_per_line * max_lines:
            MIN_LINE_LENGTH = 3  # æœ€ä½3æ–‡å­—
            split_pos = None
            split_reason = None

            # å„ªå…ˆé †ä½1: èª­ç‚¹ï¼ˆã€Œã€ã€ï¼‰ã§åˆ†å‰² - ä¸¡æ–¹ãŒ18æ–‡å­—ä»¥å†…ã®å ´åˆ
            for i in range(len(characters) - 1, -1, -1):
                if characters[i] == 'ã€':
                    first_part_len = i + 1  # ã€Œã€ã€ã‚’å«ã‚€
                    second_part_len = len(characters) - (i + 1)

                    # ä¸¡æ–¹ãŒ18æ–‡å­—ä»¥å†…ã§ã€æœ€ä½æ–‡å­—æ•°ä»¥ä¸Š
                    if (first_part_len <= max_chars_per_line and
                        second_part_len <= max_chars_per_line and
                        first_part_len >= MIN_LINE_LENGTH and
                        second_part_len >= MIN_LINE_LENGTH):
                        split_pos = i + 1
                        split_reason = "comma"
                        break

            # å„ªå…ˆé †ä½2: åŠ©è©ã®å¾Œ
            if split_pos is None:
                for i in range(len(characters) - 1, -1, -1):
                    if characters[i] in self.particles:
                        first_part_len = i + 1
                        second_part_len = len(characters) - (i + 1)

                        if (first_part_len <= max_chars_per_line and
                            second_part_len <= max_chars_per_line and
                            first_part_len >= MIN_LINE_LENGTH and
                            second_part_len >= MIN_LINE_LENGTH):
                            split_pos = i + 1
                            split_reason = "particle"
                            break

            # å„ªå…ˆé †ä½3: ã²ã‚‰ãŒãªâ†’æ¼¢å­—ã®å¢ƒç•Œ
            if split_pos is None:
                for i in range(len(characters) - 1, -1, -1):
                    if i + 1 < len(characters):
                        if self._is_hiragana(characters[i]) and self._is_kanji(characters[i + 1]):
                            first_part_len = i + 1
                            second_part_len = len(characters) - (i + 1)

                            if (first_part_len <= max_chars_per_line and
                                second_part_len <= max_chars_per_line and
                                first_part_len >= MIN_LINE_LENGTH and
                                second_part_len >= MIN_LINE_LENGTH):
                                split_pos = i + 1
                                split_reason = "hiragana_to_kanji"
                                break

            # å„ªå…ˆé †ä½4: æ¼¢å­—â†’ã²ã‚‰ãŒãªã®å¢ƒç•Œ
            if split_pos is None:
                for i in range(len(characters) - 1, -1, -1):
                    if i + 1 < len(characters):
                        if self._is_kanji(characters[i]) and self._is_hiragana(characters[i + 1]):
                            first_part_len = i + 1
                            second_part_len = len(characters) - (i + 1)

                            if (first_part_len <= max_chars_per_line and
                                second_part_len <= max_chars_per_line and
                                first_part_len >= MIN_LINE_LENGTH and
                                second_part_len >= MIN_LINE_LENGTH):
                                split_pos = i + 1
                                split_reason = "kanji_to_hiragana"
                                break

            # å„ªå…ˆé †ä½5: ã‚«ã‚¿ã‚«ãƒŠå¢ƒç•Œ
            if split_pos is None:
                for i in range(len(characters) - 1, -1, -1):
                    if i + 1 < len(characters):
                        curr_is_katakana = self._is_katakana(characters[i])
                        next_is_katakana = self._is_katakana(characters[i + 1])

                        # ã‚«ã‚¿ã‚«ãƒŠâ†’éã‚«ã‚¿ã‚«ãƒŠ ã¾ãŸã¯ éã‚«ã‚¿ã‚«ãƒŠâ†’ã‚«ã‚¿ã‚«ãƒŠ
                        if curr_is_katakana != next_is_katakana:
                            first_part_len = i + 1
                            second_part_len = len(characters) - (i + 1)

                            if (first_part_len <= max_chars_per_line and
                                second_part_len <= max_chars_per_line and
                                first_part_len >= MIN_LINE_LENGTH and
                                second_part_len >= MIN_LINE_LENGTH):
                                split_pos = i + 1
                                split_reason = "katakana_boundary"
                                break

            # é©åˆ‡ãªåˆ†å‰²ä½ç½®ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
            if split_pos:
                line1_chars = characters[:split_pos]
                line2_chars = characters[split_pos:]

                line1 = "".join(line1_chars)
                line2 = "".join(line2_chars)

                if self.splitter.remove_punctuation_in_display:
                    # å¥èª­ç‚¹ã‚’é™¤å»ï¼ˆã€Œã€ã€ã¯æ®‹ã™ï¼‰
                    line1 = "".join([c for c in line1 if c not in ["ã€‚", "ï¼", "ï¼Ÿ", "â€¦"]])
                    line2 = "".join([c for c in line2 if c not in ["ã€‚", "ï¼", "ï¼Ÿ", "â€¦"]])

                self.logger.debug(
                    f"Split at {split_reason} (36-char mode): '{line1}' / '{line2}' "
                    f"({len(line1_chars)} + {len(line2_chars)} = {len(characters)} chars)"
                )

                return [line1, line2]

            # ã™ã¹ã¦ã®æ–¹æ³•ã§åˆ†å‰²ã§ããªã„å ´åˆã¯æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.logger.debug(
                f"No suitable split point found for 36-char text, falling back to scoring method"
            )

        lines = []
        remaining_chars = characters.copy()
        remaining_punct = punctuation_positions.copy()

        # å½¢æ…‹ç´ å¢ƒç•Œã‚’æ¤œå‡ºï¼ˆå…¨ä½“ã§ä¸€åº¦ã ã‘ï¼‰
        morpheme_info = self._detect_morpheme_boundaries(characters)

        while remaining_chars and len(lines) < max_lines:
            # æœ€çµ‚è¡Œã®å‡¦ç†
            if len(lines) == max_lines - 1:
                line_text = "".join(remaining_chars)

                # æœ€çµ‚è¡ŒãŒé•·ã™ãã‚‹å ´åˆã¯è­¦å‘Šã‚’å‡ºã™
                if len(remaining_chars) > max_chars_per_line * 1.5:
                    self.logger.warning(
                        f"Last line is too long ({len(remaining_chars)} chars). "
                        f"Text may be truncated or split improperly. "
                        f"Consider using longer max_chars or multiple subtitles."
                    )

                if self.splitter.remove_punctuation_in_display:
                    # å¥èª­ç‚¹ã‚’é™¤å»ï¼ˆã€Œã€ã€ã¨ã€Œã€ã¯æ®‹ã™ï¼‰
                    line_text = "".join([c for c in line_text if c not in ["ã€‚", "ï¼", "ï¼Ÿ", "â€¦"]])
                lines.append(line_text)
                break

            # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹å½¢æ…‹ç´ æƒ…å ±ã‚’æ›´æ–°
            offset = len(characters) - len(remaining_chars)
            remaining_morpheme_info = {
                'boundaries': [b - offset for b in morpheme_info.get('boundaries', []) if b >= offset],
                'verb_adjective_positions': set([p - offset for p in morpheme_info.get('verb_adjective_positions', set()) if p >= offset])
            }

            # åˆ†å‰²ä½ç½®ã‚’æ±ºå®š
            split_pos, reason = self._find_split_position_with_score(
                text="".join(remaining_chars),
                characters=remaining_chars,
                max_chars=max_chars_per_line,
                punctuation_positions=remaining_punct,
                boundaries=self.splitter._detect_character_boundaries(remaining_chars),
                morpheme_info=remaining_morpheme_info
            )

            # ã“ã®è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            line_chars = remaining_chars[:split_pos]
            line_text = "".join(line_chars)

            if self.splitter.remove_punctuation_in_display:
                # å¥èª­ç‚¹ã‚’é™¤å»ï¼ˆã€Œã€ã€ã¨ã€Œã€ã¯æ®‹ã™ï¼‰
                line_text = "".join([c for c in line_text if c not in ["ã€‚", "ï¼", "ï¼Ÿ", "â€¦"]])

            # è¡Œã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§æœ€å°é•·ã‚’ä¿è¨¼ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„ï¼‰
            # ä»¥å‰ã® min_line_length ãƒã‚§ãƒƒã‚¯ã¯ãƒ†ã‚­ã‚¹ãƒˆæ¬ è½ã®åŸå› ã¨ãªã‚‹ãŸã‚å‰Šé™¤
            lines.append(line_text)

            # æ®‹ã‚Šã‚’æ›´æ–°
            remaining_chars = remaining_chars[split_pos:]
            # å¥èª­ç‚¹ä½ç½®ã‚’æ›´æ–°ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãšã‚‰ã™ï¼‰
            new_punct = {}
            for pos, punct in remaining_punct.items():
                if pos >= split_pos:
                    new_punct[pos - split_pos] = punct
            remaining_punct = new_punct

        # ç©ºè¡Œã‚’é™¤å¤–
        lines = [line for line in lines if line.strip()]

        return lines[:max_lines]

    def generate_subtitles_from_char_timings(
        self,
        audio_timing_data: List[Dict[str, Any]]
    ) -> List[SubtitleEntry]:
        """
        æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‹ã‚‰å­—å¹•ã‚’ç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰

        Args:
            audio_timing_data: audio_timing.jsonã®å†…å®¹

        Returns:
            å­—å¹•ãƒªã‚¹ãƒˆ
        """
        max_chars = self.max_chars_per_line * self.max_lines
        max_duration = self.max_display_duration
        min_duration = self.min_display_duration

        # ä¸€æ™‚çš„ã«å…¨å­—å¹•å€™è£œã‚’ä¿å­˜ï¼ˆçµ‚äº†æ™‚åˆ»èª¿æ•´å‰ï¼‰
        temp_subtitles = []

        for section in audio_timing_data:
            offset = section.get("offset", 0.0)

            # ğŸ†• ã‚¿ã‚¤ãƒˆãƒ«å­—å¹•ã‚’è¿½åŠ ï¼ˆsection_titleãŒã‚ã‚‹å ´åˆï¼‰
            title_timing = section.get("title_timing")
            if title_timing:
                title_text = title_timing.get("text", "")
                title_start = offset + title_timing.get("start_time", 0.0)
                title_end = offset + title_timing.get("end_time", 0.0)

                # ã‚¿ã‚¤ãƒˆãƒ«å­—å¹•ã‚’ä¸€æ™‚ä¿å­˜ï¼ˆspecial_typeãƒãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰
                temp_subtitles.append({
                    "start": title_start,
                    "end": title_end,
                    "original_duration": title_end - title_start,
                    "lines": [title_text, "", ""],
                    "special_type": "section_title"  # ãƒãƒ¼ã‚«ãƒ¼
                })

                self.logger.debug(f"Added title subtitle: {title_text} ({title_start:.2f}s - {title_end:.2f}s)")

            # ğŸ†• narration_timingã‹ã‚‰æ–‡å­—ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
            narration_timing = section.get("narration_timing", {})
            if not narration_timing:
                self.logger.warning(f"Section {section.get('section_id')} has no narration_timing")
                continue
            
            text = narration_timing.get("text", section.get("text", ""))
            characters = narration_timing.get("characters", [])
            char_start_times = narration_timing.get("char_start_times", [])
            char_end_times = narration_timing.get("char_end_times", [])
            
            # ğŸ†• ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®é–‹å§‹æ™‚åˆ»ã‚’offsetã«åŠ ç®—
            narration_start = narration_timing.get("start_time", 0.0)
            if char_start_times:
                # ç›¸å¯¾æ™‚åˆ»ã‚’çµ¶å¯¾æ™‚åˆ»ã«å¤‰æ›ï¼ˆoffset + narration_startã‚’åŠ ç®—ï¼‰
                char_start_times = [offset + narration_start + t for t in char_start_times]
            if char_end_times:
                char_end_times = [offset + narration_start + t for t in char_end_times]

            if not characters or len(characters) != len(char_start_times):
                self.logger.warning(f"Section {section.get('section_id')} has invalid timing data")
                continue

            # ã‚¹ãƒ†ãƒƒãƒ—1: ã¾ãš \n ã§åˆ†å‰²ï¼ˆæ˜ç¤ºçš„ãªæ”¹è¡Œã‚’å„ªå…ˆï¼‰
            subsections = self._split_section_by_newline(
                text,
                characters,
                char_start_times,
                char_end_times
            )

            # å„ã‚µãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†
            for subsection in subsections:
                subsection_chars = subsection["characters"]
                subsection_start_times = subsection["start_times"]
                subsection_end_times = subsection["end_times"]

                if not subsection_chars:
                    continue

                # å¥èª­ç‚¹ä½ç½®ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
                # ä¿®æ­£å¾Œ: charactersã«å¥èª­ç‚¹ãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€ç›´æ¥æ¤œå‡º
                punctuation_positions = self._find_punctuation_positions_from_characters(subsection_chars)

                # æ–‡å­—ç¨®å¢ƒç•Œã‚’æ¤œå‡º
                boundaries = self.splitter._detect_character_boundaries(subsection_chars)

                # ã‚¹ãƒ†ãƒƒãƒ—2: å¥èª­ç‚¹ã§å¤§ã¾ã‹ã«åˆ†å‰²
                # ğŸ†• offsetã¯æ—¢ã«char_start_times/char_end_timesã«åŠ ç®—æ¸ˆã¿ãªã®ã§ã€0ã‚’æ¸¡ã™
                chunks = self._split_by_punctuation(
                    subsection_chars,
                    punctuation_positions,
                    subsection_start_times,
                    subsection_end_times,
                    0.0  # æ—¢ã«çµ¶å¯¾æ™‚åˆ»ã«å¤‰æ›æ¸ˆã¿
                )

                # å„ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
                for chunk in chunks:
                    chunk_chars = chunk["characters"]
                    chunk_start_times = chunk["start_times"]
                    chunk_end_times = chunk["end_times"]

                    if not chunk_chars:
                        continue

                    # ãƒãƒ£ãƒ³ã‚¯ãŒmax_charsã‚’è¶…ãˆã‚‹å ´åˆã¯å†åˆ†å‰²
                    if len(chunk_chars) > max_chars:
                        sub_chunks = self._split_large_chunk(
                            chunk_chars,
                            chunk_start_times,
                            chunk_end_times,
                            max_chars,
                            boundaries
                        )
                    else:
                        sub_chunks = [chunk]

                    # å„ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯ã‚’å­—å¹•ã‚¨ãƒ³ãƒˆãƒªã«å¤‰æ›ï¼ˆä¸€æ™‚ä¿å­˜ï¼‰
                    for sub_chunk in sub_chunks:
                        sub_chars = sub_chunk["characters"]
                        sub_start_times = sub_chunk["start_times"]
                        sub_end_times = sub_chunk["end_times"]

                        if not sub_chars:
                            continue

                        # é–‹å§‹ãƒ»çµ‚äº†æ™‚åˆ»
                        subtitle_start = sub_start_times[0]
                        subtitle_end = sub_end_times[-1]
                        original_duration = subtitle_end - subtitle_start

                        # å¥èª­ç‚¹ä½ç½®ã¨å¢ƒç•Œã‚’å†è¨ˆç®—ï¼ˆã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯ç”¨ï¼‰
                        # ä¿®æ­£å¾Œ: charactersã«å¥èª­ç‚¹ãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€ç›´æ¥æ¤œå‡º
                        sub_punct = self._find_punctuation_positions_from_characters(sub_chars)
                        sub_boundaries = self.splitter._detect_character_boundaries(sub_chars)

                        # è¤‡æ•°è¡Œã«åˆ†å‰²
                        lines = self._split_into_balanced_lines(
                            text="".join(sub_chars),
                            characters=sub_chars,
                            max_chars_per_line=self.max_chars_per_line,
                            max_lines=self.max_lines,
                            punctuation_positions=sub_punct,
                            boundaries=sub_boundaries
                        )

                        # ç©ºè¡Œã‚’åŸ‹ã‚ã‚‹
                        while len(lines) < 3:
                            lines.append("")

                        # ä¸€æ™‚çš„ã«ä¿å­˜ï¼ˆèª¿æ•´å‰ï¼‰
                        temp_subtitles.append({
                            "start": subtitle_start,
                            "end": subtitle_end,
                            "original_duration": original_duration,
                            "lines": lines,
                            "special_type": None  # é€šå¸¸ã®å­—å¹•
                        })

        # å…¨å­—å¹•ã®çµ‚äº†æ™‚åˆ»ã‚’èª¿æ•´ï¼ˆé‡ãªã‚Šé˜²æ­¢ï¼‰
        subtitles = []
        subtitle_index = 1

        for i, temp_sub in enumerate(temp_subtitles):
            subtitle_start = temp_sub["start"]
            subtitle_end = temp_sub["end"]
            original_duration = temp_sub["original_duration"]
            lines = temp_sub["lines"]

            # æ¬¡ã®å­—å¹•ãŒã‚ã‚‹ã‹ç¢ºèª
            next_start = None
            if i + 1 < len(temp_subtitles):
                next_start = temp_subtitles[i + 1]["start"]

            # ğŸ”¥ ä¿®æ­£: æ–‡å­—ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ä½¿ç”¨æ™‚ã¯ subtitle_gap ã‚’é©ç”¨ã—ãªã„
            # ç†ç”±: audio_timing.json ã‹ã‚‰å–å¾—ã—ãŸæ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯æ—¢ã«æ­£ç¢ºãªãŸã‚
            # æœ€å°ã‚®ãƒ£ãƒƒãƒ—ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåŸºæº–ã§è¨ˆç®—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å¢ƒç•Œã§ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’è€ƒæ…®ï¼‰
            # config ã‹ã‚‰ fps ã‚’å–å¾— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30fps)
            fps = self.config.get("video", {}).get("fps") or self.config.get("fps", 30)
            frame_duration = 1.0 / fps  # 30fps ãªã‚‰ 0.033ç§’
            # æœ€å°ã‚®ãƒ£ãƒƒãƒ—ã¯ 3ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã‚’ç¢ºä¿ï¼ˆè¦–è¦šçš„ã«ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
            MIN_GAP = frame_duration * 3  # 30fps ãªã‚‰ 0.1ç§’

            # è¡¨ç¤ºæ™‚é–“ã®åˆ¶ç´„ã‚’é©ç”¨ï¼ˆæ¬¡ã®å­—å¹•ã‚’è€ƒæ…®ï¼‰
            # éŸ³å£°ã®å®Ÿéš›ã®é•·ã•ã‚’åŸºæœ¬ã¨ã—ã€å¿…è¦ã«å¿œã˜ã¦èª¿æ•´ã™ã‚‹
            duration = subtitle_end - subtitle_start

            if duration < min_duration:
                # min_display_duration ã‚’é©ç”¨ï¼ˆçŸ­ã™ãã‚‹å ´åˆï¼‰
                ideal_end = subtitle_start + min_duration

                if self.prevent_overlap and next_start is not None:
                    # æ¬¡ã®å­—å¹•ã¨ã®é‡ãªã‚Šã‚’é˜²ãï¼ˆæœ€å°ã‚®ãƒ£ãƒƒãƒ—ã®ã¿ï¼‰
                    max_allowed_end = next_start - MIN_GAP

                    if self.overlap_priority == "next_subtitle":
                        # æ¬¡ã®å­—å¹•ã‚’å„ªå…ˆï¼ˆé‡ãªã‚‰ãªã„ã‚ˆã†ã«èª¿æ•´ï¼‰
                        subtitle_end = min(ideal_end, max_allowed_end)
                    else:
                        # min_duration ã‚’å„ªå…ˆï¼ˆé‡ãªã£ã¦ã‚‚å»¶é•·ï¼‰
                        subtitle_end = ideal_end
                else:
                    subtitle_end = ideal_end

            elif duration > max_duration:
                # éŸ³å£°ãŒé•·ã„å ´åˆã®å‡¦ç†
                # åŸå‰‡: éŸ³å£°ã®å®Ÿéš›ã®é•·ã•ã‚’å°Šé‡ï¼ˆæ¬¡ã®å­—å¹•ã¨é‡ãªã‚‰ãªã„é™ã‚Šï¼‰
                if self.prevent_overlap and next_start is not None:
                    max_allowed_end = next_start - MIN_GAP

                    if subtitle_end <= max_allowed_end:
                        # éŸ³å£°ã®å®Ÿéš›ã®é•·ã•ã‚’ç¶­æŒï¼ˆæ¬¡ã®å­—å¹•ã¨é‡ãªã‚‰ãªã„ï¼‰
                        pass
                    else:
                        # æ¬¡ã®å­—å¹•ã¨é‡ãªã‚‹ã®ã§èª¿æ•´
                        subtitle_end = max_allowed_end
                else:
                    # æ¬¡ã®å­—å¹•ãŒãªã„å ´åˆã¯ max_duration ã§åˆ¶é™
                    ideal_end = subtitle_start + max_duration
                    subtitle_end = min(subtitle_end, ideal_end)

            else:
                # duration ãŒ min ã¨ max ã®ç¯„å›²å†…ã«ã‚ã‚‹å ´åˆ
                # éŸ³å£°ã®å®Ÿéš›ã®é•·ã•ã‚’ç¶­æŒ

                # ğŸ”¥ NEW: å¥ç‚¹ã§çµ‚ã‚ã‚‹å ´åˆã¯å»¶é•·ã‚’è©¦ã¿ã‚‹
                last_char = ""
                for line in reversed(lines):
                    if line:
                        last_char = line[-1]
                        break

                if last_char in ["ã€‚", "ï¼", "ï¼Ÿ", "!", "?"]:
                    # å¥ç‚¹ã§çµ‚ã‚ã‚‹å­—å¹• â†’ å»¶é•·ã‚’æ¤œè¨
                    if self.prevent_overlap and next_start is not None:
                        max_allowed_end = next_start - MIN_GAP
                        available_time = max_allowed_end - subtitle_end

                        # ä½™è£•ãŒ0.5ç§’ä»¥ä¸Šã‚ã‚Œã°60%å»¶é•·
                        if available_time >= 0.5:
                            extension = available_time * 0.6
                            subtitle_end = subtitle_end + extension

                            self.logger.debug(
                                f"Subtitle {subtitle_index}: Extended end_time by {extension:.3f}s "
                                f"for punctuation (available: {available_time:.3f}s, "
                                f"new end: {subtitle_end:.3f}s)"
                            )
                        elif available_time > 0:
                            # ä½™è£•ã¯å°‘ãªã„ãŒã€æ¬¡ã®å­—å¹•ã¨ã¯é‡ãªã‚‰ãªã„ã‚ˆã†ã«èª¿æ•´
                            if subtitle_end > max_allowed_end:
                                subtitle_end = max_allowed_end
                    elif next_start is None:
                        # æœ€å¾Œã®å­—å¹•ï¼ˆæ¬¡ã®å­—å¹•ãŒãªã„ï¼‰ã®å ´åˆã¯ä¸€å¾‹0.5ç§’å»¶é•·
                        extension = 0.5
                        subtitle_end = subtitle_end + extension

                        self.logger.debug(
                            f"Subtitle {subtitle_index} (LAST): Extended end_time by {extension:.3f}s "
                            f"for punctuation (new end: {subtitle_end:.3f}s)"
                        )
                else:
                    # å¥ç‚¹ä»¥å¤– â†’ é€šå¸¸ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ã¿
                    if self.prevent_overlap and next_start is not None:
                        max_allowed_end = next_start - MIN_GAP
                        if subtitle_end > max_allowed_end:
                            subtitle_end = max_allowed_end

            # æœ€çµ‚ãƒã‚§ãƒƒã‚¯: subtitle_end ãŒ subtitle_start ã‚ˆã‚Šå°ã•ããªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
            # ï¼ˆæ¬¡ã®å­—å¹•ã®é–‹å§‹æ™‚åˆ»ãŒç¾åœ¨ã®å­—å¹•ã‚ˆã‚Šå‰ã«ã‚ã‚‹ç•°å¸¸ã‚±ãƒ¼ã‚¹å¯¾ç­–ï¼‰
            MIN_SUBTITLE_DURATION = 0.1  # æœ€ä½0.1ç§’
            if subtitle_end <= subtitle_start:
                self.logger.warning(
                    f"Subtitle {subtitle_index}: end_time ({subtitle_end:.3f}s) <= start_time ({subtitle_start:.3f}s). "
                    f"Adjusting to minimum duration ({MIN_SUBTITLE_DURATION}s)."
                )
                subtitle_end = subtitle_start + MIN_SUBTITLE_DURATION

            # æœ€çµ‚çš„ãªå­—å¹•ã‚’ä½œæˆ
            subtitles.append(SubtitleEntry(
                index=subtitle_index,
                start_time=subtitle_start,
                end_time=subtitle_end,
                text_line1=lines[0] if len(lines) > 0 else "",
                text_line2=lines[1] if len(lines) > 1 else "",
                special_type=temp_sub.get("special_type")  # special_typeã‚’å–å¾—
            ))
            subtitle_index += 1

        self.logger.info(f"Generated {len(subtitles)} subtitles from character timings")
        return subtitles
    def _split_section_by_newline(
        self,
        text: str,
        characters: List[str],
        start_times: List[float],
        end_times: List[float]
    ) -> List[Dict[str, Any]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’ \n ã§åˆ†å‰²ï¼ˆæ˜ç¤ºçš„ãªæ”¹è¡Œã‚’å„ªå…ˆï¼‰
        
        ãŸã ã—ã€éµã‹ã£ã“å†…ã®æ”¹è¡Œã¯ç„¡è¦–ã™ã‚‹ã€‚

        æ–‡å­—åˆ—ãƒãƒƒãƒãƒ³ã‚°ã§ text ã¨ characters ã®å¯¾å¿œã‚’å–ã‚‹ã€‚
        è¨˜å·ï¼ˆã‚«ãƒƒã‚³é¡ã€ç©ºç™½ï¼‰ã¯é™¤å¤–ã—ã¦ãƒãƒƒãƒãƒ³ã‚°ã€‚å¥èª­ç‚¹ã¯å«ã‚ã‚‹ã€‚

        Args:
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ\n ã‚’å«ã‚€å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
            characters: æ–‡å­—é…åˆ—
            start_times: å„æ–‡å­—ã®é–‹å§‹æ™‚é–“
            end_times: å„æ–‡å­—ã®çµ‚äº†æ™‚é–“

        Returns:
            ã‚µãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆï¼ˆå„ã‚µãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ characters, start_times, end_times ã‚’æŒã¤ï¼‰
        """
        # ğŸ”¥ NEW: éµã‹ã£ã“å†…ã®æ”¹è¡Œã‚’å‰Šé™¤ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
        cleaned_characters = []
        cleaned_start_times = []
        cleaned_end_times = []
        in_quotation = False

        for i, char in enumerate(characters):
            if char == 'ã€Œ':
                in_quotation = True
                cleaned_characters.append(char)
                cleaned_start_times.append(start_times[i])
                cleaned_end_times.append(end_times[i])
            elif char == 'ã€':
                in_quotation = False
                cleaned_characters.append(char)
                cleaned_start_times.append(start_times[i])
                cleaned_end_times.append(end_times[i])
            elif char == '\n' and in_quotation:
                # éµã‹ã£ã“å†…ã®æ”¹è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚‚å‰Šé™¤ï¼‰
                continue
            else:
                cleaned_characters.append(char)
                cleaned_start_times.append(start_times[i])
                cleaned_end_times.append(end_times[i])

        # ä»¥é™ã€cleaned_* ã‚’ä½¿ç”¨
        characters = cleaned_characters
        start_times = cleaned_start_times
        end_times = cleaned_end_times

        if '\n' not in text:
            # \n ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™ï¼ˆæ”¹è¡Œå‰Šé™¤å¾Œï¼‰
            return [{
                "characters": characters,
                "start_times": start_times,
                "end_times": end_times
            }]

        # éµã‹ã£ã“å†…ã®æ”¹è¡Œã‚’ç„¡è¦–ã—ã¦åˆ†å‰²
        text_parts = []
        current_part = ""
        in_quotation = False
        
        for char in text:
            if char == 'ã€Œ':
                in_quotation = True
                current_part += char
            elif char == 'ã€':
                in_quotation = False
                current_part += char
            elif char == '\n' and not in_quotation:
                # éµã‹ã£ã“å¤–ã®æ”¹è¡Œã§ã®ã¿åˆ†å‰²
                if current_part.strip():
                    text_parts.append(current_part.strip())
                current_part = ""
            else:
                current_part += char
        
        # æœ€å¾Œã®éƒ¨åˆ†ã‚’è¿½åŠ 
        if current_part.strip():
            text_parts.append(current_part.strip())

        if len(text_parts) <= 1:
            # åˆ†å‰²ã®å¿…è¦ãŒãªã„ï¼ˆæ”¹è¡Œå‰Šé™¤æ¸ˆã¿ï¼‰
            return [{
                "characters": characters,
                "start_times": start_times,
                "end_times": end_times
            }]

        # characters ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        chars_str = ''.join(characters)

        # é™¤å¤–ã™ã‚‹è¨˜å·ï¼ˆã‚«ãƒƒã‚³é¡ã€ç©ºç™½ã®ã¿ã€‚å¥èª­ç‚¹ã¯å«ã‚ã‚‹ï¼‰
        exclude_symbols = set([' ', 'ã€€', 'ã€Œ', 'ã€', 'ã€', 'ã€', 'ï¼ˆ', 'ï¼‰', '(', ')'])

        subsections = []
        search_start = 0
        match_failed = False

        for part in text_parts:
            # part ã‹ã‚‰è¨˜å·ã‚’é™¤å¤–
            part_clean = ''.join([c for c in part if c not in exclude_symbols])

            if not part_clean:
                continue

            # chars_str ã‹ã‚‰ part_clean ã‚’æ¢ã™ï¼ˆsearch_start ã‹ã‚‰ï¼‰
            pos = chars_str.find(part_clean, search_start)

            if pos == -1:
                # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è­¦å‘Šã‚’å‡ºã—ã¦ã€åˆ†å‰²ã‚’è«¦ã‚ã‚‹
                self.logger.warning(
                    f"Could not match newline-separated part: '{part[:30]}...' "
                    f"(cleaned: '{part_clean[:30]}...'). "
                    f"Skipping newline split for this section."
                )
                match_failed = True
                break

            end_pos = pos + len(part_clean)

            subsections.append({
                "characters": characters[pos:end_pos],
                "start_times": start_times[pos:end_pos],
                "end_times": end_times[pos:end_pos]
            })

            search_start = end_pos

        # ãƒãƒƒãƒãƒ³ã‚°ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€åˆ†å‰²ã‚’è«¦ã‚ã¦å…¨ä½“ã‚’è¿”ã™
        if match_failed or not subsections:
            return [{
                "characters": characters,
                "start_times": start_times,
                "end_times": end_times
            }]

        return subsections
    def _split_by_punctuation(
        self,
        characters: List[str],
        punctuation_positions: Dict[int, str],
        start_times: List[float],
        end_times: List[float],
        offset: float
    ) -> List[Dict[str, Any]]:
        """
        å¥èª­ç‚¹ã§å¤§ã¾ã‹ã«åˆ†å‰²ï¼ˆã€Œã€‚ã€ã®ã¿ã§åˆ†å‰²ã€ã€Œã€ã€ã§ã¯åˆ†å‰²ã—ãªã„ï¼‰
        
        ãŸã ã—ã€éµã‹ã£ã“å†…ã®å¥èª­ç‚¹ã§ã¯åˆ†å‰²ã—ãªã„ã€‚

        Returns:
            ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆï¼ˆå„ãƒãƒ£ãƒ³ã‚¯ã¯ characters, start_times, end_times ã‚’æŒã¤ï¼‰
        """
        chunks = []
        current_chars = []
        current_starts = []
        current_ends = []
        in_quotation = False  # éµã‹ã£ã“å†…ãƒ•ãƒ©ã‚°

        for i, char in enumerate(characters):
            # æ”¹è¡Œãƒ»ç©ºç™½ã¯ãƒãƒ£ãƒ³ã‚¯ã«å«ã‚ãªã„ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã‚ºãƒ¬ã‚’é˜²ãï¼‰
            if char in ['\n', '\r', ' ', '\t']:
                continue

            current_chars.append(char)
            current_starts.append(start_times[i] + offset)
            current_ends.append(end_times[i] + offset)

            # éµã‹ã£ã“ã®é–‹é–‰ã‚’è¿½è·¡
            if char == 'ã€Œ':
                in_quotation = True
            elif char == 'ã€':
                in_quotation = False

            # ã€Œã€‚ã€ã€Œï¼ã€ã€Œï¼Ÿã€ã®æ–‡å­—ã‚’å«ã‚ã¦åˆ†å‰²
            # éµã‹ã£ã“å†…ã§ã‚‚ã€30æ–‡å­—è¶…ãˆãŸå ´åˆã¯ã€Œã€ã€ã§åˆ†å‰²
            current_punct = punctuation_positions.get(i)
            should_split = (
                # é€šå¸¸ã®å¥ç‚¹ã§ã¯åˆ†å‰²ï¼ˆéµã‹ã£ã“å¤–ã®ã¿ï¼‰
                (current_punct in ["ã€‚", "ï¼", "ï¼Ÿ"] and not in_quotation)
                # æœ€å¾Œã®æ–‡å­—ã¯å¿…ãšåˆ†å‰²
                or i == len(characters) - 1
                # ğŸ”¥ NEW: éµã‹ã£ã“å†…ã§ã‚‚30æ–‡å­—è¶…ãˆãŸã‚‰ã€Œã€ã€ã§åˆ†å‰²
                or (in_quotation and current_punct == "ã€" and len(current_chars) > 30)
            )

            if should_split:
                if current_chars:
                    chunks.append({
                        "characters": current_chars.copy(),
                        "start_times": current_starts.copy(),
                        "end_times": current_ends.copy()
                    })
                    current_chars = []
                    current_starts = []
                    current_ends = []

        # æ®‹ã‚ŠãŒã‚ã‚Œã°è¿½åŠ 
        if current_chars:
            chunks.append({
                "characters": current_chars,
                "start_times": current_starts,
                "end_times": current_ends
            })

        return chunks
    def _split_large_chunk(
        self,
        characters: List[str],
        start_times: List[float],
        end_times: List[float],
        max_chars: int,
        boundaries: Dict[str, List[int]]
    ) -> List[Dict[str, Any]]:
        """
        å¤§ããªãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹å¼ã§åˆ†å‰²

        æ®‹ã‚ŠãŒ10æ–‡å­—æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«èª¿æ•´ã™ã‚‹ã€‚
        """
        MIN_CHUNK_LENGTH = 10  # æœ€å°ãƒãƒ£ãƒ³ã‚¯é•·

        chunks = []
        remaining_chars = characters.copy()
        remaining_starts = start_times.copy()
        remaining_ends = end_times.copy()

        # å½¢æ…‹ç´ å¢ƒç•Œã‚’æ¤œå‡ºï¼ˆå…¨ä½“ã§ä¸€åº¦ã ã‘ï¼‰
        morpheme_info = self._detect_morpheme_boundaries(characters)

        while remaining_chars:
            if len(remaining_chars) <= max_chars:
                # æ®‹ã‚Šã‚’ãã®ã¾ã¾è¿½åŠ 
                chunks.append({
                    "characters": remaining_chars,
                    "start_times": remaining_starts,
                    "end_times": remaining_ends
                })
                break

            # åˆ†å‰²ä½ç½®ã®ä¸Šé™ã‚’è¨ˆç®—ï¼ˆæ®‹ã‚ŠãŒ10æ–‡å­—æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«ï¼‰
            # ä¾‹: 40æ–‡å­—ãªã‚‰ã€max_split_pos = 40 - 10 = 30
            max_split_pos = len(remaining_chars) - MIN_CHUNK_LENGTH

            # èª¿æ•´ã•ã‚ŒãŸ max_charsï¼ˆé€šå¸¸ã¯36ã ãŒã€æ®‹ã‚ŠãŒçŸ­ããªã‚Šã™ãã‚‹å ´åˆã¯å°ã•ãã™ã‚‹ï¼‰
            adjusted_max_chars = min(max_chars, max_split_pos)

            # adjusted_max_chars ãŒ MIN_CHUNK_LENGTH ã‚ˆã‚Šå°ã•ã„å ´åˆã¯ã€åˆ†å‰²ã›ãšã«å…¨ä½“ã‚’1ã¤ã«
            if adjusted_max_chars < MIN_CHUNK_LENGTH:
                chunks.append({
                    "characters": remaining_chars,
                    "start_times": remaining_starts,
                    "end_times": remaining_ends
                })
                break

            # å„ªå…ˆé †ä½1: 36æ–‡å­—ï¼ˆmax_charsï¼‰ã‚ˆã‚Šå‰ã§æœ€ã‚‚å¾Œã‚ã®ã€Œã€ã€ã‚’æ¢ã™
            comma_positions = [i for i, c in enumerate(remaining_chars) if c == 'ã€' and i < max_chars]

            split_pos = None
            reason = ""

            if comma_positions:
                # æœ€ã‚‚å¾Œã‚ã®ã€Œã€ã€ã§åˆ†å‰²ï¼ˆã€Œã€ã€ã‚’å«ã‚ã‚‹ï¼‰
                split_pos = comma_positions[-1] + 1
                reason = "comma_split_priority"

                self.logger.debug(
                    f"Found comma at position {comma_positions[-1]} "
                    f"(text length: {len(remaining_chars)}, max_chars: {max_chars})"
                )
            else:
                # å„ªå…ˆé †ä½2: ã€Œã€ã€ãŒãªã„å ´åˆã¯æ—¢å­˜ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
                # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹å½¢æ…‹ç´ æƒ…å ±ã‚’æ›´æ–°
                offset = len(characters) - len(remaining_chars)
                remaining_morpheme_info = {
                    'boundaries': [b - offset for b in morpheme_info.get('boundaries', []) if b >= offset],
                    'verb_adjective_positions': set([p - offset for p in morpheme_info.get('verb_adjective_positions', set()) if p >= offset])
                }

                # åˆ†å‰²ä½ç½®ã‚’æ±ºå®š
                sub_boundaries = self.splitter._detect_character_boundaries(remaining_chars)
                split_pos, reason = self._find_split_position_with_score(
                    text="".join(remaining_chars),
                    characters=remaining_chars,
                    max_chars=adjusted_max_chars,
                    punctuation_positions={},  # å¥èª­ç‚¹ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿
                    boundaries=sub_boundaries,
                    morpheme_info=remaining_morpheme_info
                )

            # ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
            chunks.append({
                "characters": remaining_chars[:split_pos],
                "start_times": remaining_starts[:split_pos],
                "end_times": remaining_ends[:split_pos]
            })

            # æ®‹ã‚Šã‚’æ›´æ–°
            remaining_chars = remaining_chars[split_pos:]
            remaining_starts = remaining_starts[split_pos:]
            remaining_ends = remaining_ends[split_pos:]

        return chunks

