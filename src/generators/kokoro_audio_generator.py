"""
Kokoro TTSéŸ³å£°ç”Ÿæˆå™¨

Kokoro TTS FastAPIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã€‚
å®Œå…¨ç„¡æ–™ã§ã€å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç›´æ¥å–å¾—ã§ãã‚‹ã€‚
"""

import requests
import base64
import json
import os
import logging
import tempfile
import re
import io
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Any

from src.utils.whisper_timing import WhisperTimingExtractor, WHISPER_AVAILABLE
from src.utils.elevenlabs_forced_alignment import (
    create_elevenlabs_aligner,
    ELEVENLABS_FA_AVAILABLE
)



class KokoroAudioGenerator:
    """
    Kokoro TTS FastAPIã‚’ä½¿ç”¨ã—ãŸéŸ³å£°ç”Ÿæˆã‚¯ãƒ©ã‚¹

    å®Œå…¨ç„¡æ–™ã®TTSã‚·ã‚¹ãƒ†ãƒ ã§ã€å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç›´æ¥å–å¾—ã§ãã‚‹ã€‚
    """

    def __init__(
        self,
        api_url: Optional[str] = None,
        voice: str = "jf_alpha",
        speed: float = 1.0,
        response_format: str = "mp3",
        logger: Optional[logging.Logger] = None,
        whisper_config: Optional[Dict[str, Any]] = None,
        punctuation_pause_config: Optional[Dict[str, Any]] = None,
        use_elevenlabs_fa: bool = True,
        elevenlabs_api_key: Optional[str] = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            api_url: Kokoro FastAPI ã®ãƒ™ãƒ¼ã‚¹URLï¼ˆç’°å¢ƒå¤‰æ•° KOKORO_API_URL ã‚’å„ªå…ˆï¼‰
            voice: ä½¿ç”¨ã™ã‚‹éŸ³å£°åï¼ˆaf_bella, af_sarah, af_skyç­‰ï¼‰
            speed: é€Ÿåº¦ï¼ˆ0.5-2.0ï¼‰
            response_format: å‡ºåŠ›å½¢å¼ï¼ˆmp3, wav, opus, flacï¼‰
            logger: ãƒ­ã‚¬ãƒ¼
            whisper_config: Whisperè¨­å®š {"enabled": bool, "model": str, "language": str}
            punctuation_pause_config: å¥ç‚¹ã§ã®é–“éš”åˆ¶å¾¡è¨­å®š
            use_elevenlabs_fa: ElevenLabs Forced Alignmentã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            elevenlabs_api_key: ElevenLabs API Keyï¼ˆç’°å¢ƒå¤‰æ•° ELEVENLABS_API_KEY ã‚’å„ªå…ˆï¼‰

        Raises:
            ConnectionError: APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ããªã„å ´åˆ
        """
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰URLã‚’å–å¾—ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å„ªå…ˆï¼‰
        self.api_url = os.getenv("KOKORO_API_URL", api_url or "http://localhost:8880")
        self.voice = voice
        self.speed = speed
        self.response_format = response_format
        self.logger = logger or logging.getLogger(__name__)

        # Whisperè¨­å®šï¼ˆåˆæœŸåŒ–ã¯ã—ãªã„ï¼‰
        self.whisper_config = whisper_config or {"enabled": True, "model": "base", "language": "ja"}

        # å¥ç‚¹ã§ã®é–“éš”åˆ¶å¾¡è¨­å®š
        self.punctuation_pause_config = punctuation_pause_config or {"enabled": False}

        # ğŸ”¥ æ–°è¦è¿½åŠ : ElevenLabs Forced Alignmentè¨­å®š
        self.use_elevenlabs_fa = use_elevenlabs_fa
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰API Keyã‚’å–å¾—ï¼ˆå¼•æ•°ã‚’å„ªå…ˆï¼‰
        self.elevenlabs_api_key = elevenlabs_api_key or os.getenv("ELEVENLABS_API_KEY")
        self.elevenlabs_aligner = None

        if self.use_elevenlabs_fa:
            if not self.elevenlabs_api_key:
                self.logger.warning(
                    "use_elevenlabs_fa is True but elevenlabs_api_key is not set. "
                    "Falling back to Whisper."
                )
                self.use_elevenlabs_fa = False
            elif not ELEVENLABS_FA_AVAILABLE:
                self.logger.warning(
                    "ElevenLabs Forced Alignment is not available (requests library missing). "
                    "Falling back to Whisper."
                )
                self.use_elevenlabs_fa = False
            else:
                self.elevenlabs_aligner = create_elevenlabs_aligner(
                    api_key=self.elevenlabs_api_key,
                    logger=self.logger
                )
                if self.elevenlabs_aligner:
                    self.logger.info("âœ“ ElevenLabs Forced Alignment enabled")
                else:
                    self.logger.warning("Failed to create ElevenLabs aligner. Falling back to Whisper.")
                    self.use_elevenlabs_fa = False

        # ğŸ”¥ å¤‰æ›´ï¼š__init__ã§ã®åˆæœŸåŒ–ã¯ä¸è¦ï¼ˆå„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§éƒ½åº¦åˆæœŸåŒ–ï¼‰
        # WhisperãŒåˆ©ç”¨å¯èƒ½ã‹ã ã‘ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        if self.whisper_config.get("enabled", True) and WHISPER_AVAILABLE:
            self.logger.info("Whisper is available (will initialize per section as fallback)")
        else:
            self.logger.warning("Whisper not available. Timestamps will not be available if ElevenLabs FA fails.")

        # APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        self._verify_api_connection()

    def _verify_api_connection(self):
        """APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
        try:
            response = requests.get(f"{self.api_url}/v1/audio/voices", timeout=5)
            response.raise_for_status()
            voices = response.json()["voices"]
            self.logger.info(f"Kokoro APIæ¥ç¶šæˆåŠŸã€‚åˆ©ç”¨å¯èƒ½ãªéŸ³å£°: {len(voices)}å€‹")

            # é¸æŠã—ãŸéŸ³å£°ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if self.voice not in voices:
                self.logger.warning(
                    f"æŒ‡å®šã•ã‚ŒãŸéŸ³å£° '{self.voice}' ã¯åˆ©ç”¨å¯èƒ½ãƒªã‚¹ãƒˆã«ã‚ã‚Šã¾ã›ã‚“ã€‚"
                    f"åˆ©ç”¨å¯èƒ½ãªéŸ³å£°: {voices[:10]}..."
                )
        except requests.exceptions.ConnectionError:
            error_msg = (
                f"Kokoro FastAPI ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“: {self.api_url}\n"
                f"ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§èµ·å‹•ã—ã¦ãã ã•ã„:\n"
                f"  docker-compose -f docker-compose-kokoro.yml up -d"
            )
            self.logger.error(error_msg)
            raise ConnectionError(error_msg)
        except Exception as e:
            self.logger.error(f"Kokoro APIæ¥ç¶šå¤±æ•—: {e}")
            raise ConnectionError(f"Kokoro APIæ¥ç¶šå¤±æ•—: {e}")

    def _split_by_punctuation(self, text: str) -> List[str]:
        """
        å¥ç‚¹ã§æ–‡ã‚’åˆ†å‰²

        Args:
            text: åˆ†å‰²å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            å¥ç‚¹ã§åˆ†å‰²ã•ã‚ŒãŸæ–‡ã®ãƒªã‚¹ãƒˆ
        """
        # ã€Œã€‚ã€ã€Œï¼ã€ã€Œï¼Ÿã€ã§åˆ†å‰²ã—ã€åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¿æŒ
        segments = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)

        # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’å‰ã®æ–‡ã«çµåˆ
        result = []
        for i in range(0, len(segments) - 1, 2):
            if segments[i]:
                result.append(segments[i] + segments[i + 1])

        # æœ€å¾Œã®æ–‡ï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ãŒãªã„å ´åˆï¼‰
        if len(segments) % 2 == 1 and segments[-1]:
            result.append(segments[-1])

        return result

    def _generate_single_audio(self, text: str) -> str:
        """
        å˜ä¸€ã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆï¼ˆBase64ã‚’è¿”ã™ï¼‰

        Args:
            text: ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿
        """
        url = f"{self.api_url}/v1/audio/speech"

        payload = {
            "model": "kokoro",
            "input": text,
            "voice": self.voice,
            "speed": self.speed,
            "response_format": self.response_format
        }

        try:
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
            content_type = response.headers.get('content-type', '')

            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            if 'application/json' in content_type:
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆï¼ˆBase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ï¼‰
                result = response.json()
                audio_base64 = result.get("audio", "")
                if not audio_base64:
                    raise ValueError("API returned empty audio field")
            else:
                # ãƒã‚¤ãƒŠãƒªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆï¼ˆOpenAIäº’æ›APIï¼‰
                audio_bytes = response.content
                if not audio_bytes:
                    raise ValueError("API returned empty audio data")
                # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

            return audio_base64

        except Exception as e:
            self.logger.error(f"Error generating audio: {e}", exc_info=True)
            raise

    def _create_silence_file(self, duration: float, output_path: Path):
        """
        ffmpegã‚’ä½¿ç”¨ã—ã¦ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ

        Args:
            duration: ç„¡éŸ³ã®é•·ã•ï¼ˆç§’ï¼‰
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'anullsrc=r=44100:cl=mono',
            '-t', str(duration),
            '-acodec', 'libmp3lame',
            '-b:a', '128k',
            '-y',
            str(output_path)
        ]

        try:
            result = subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
            self.logger.debug(f"Created silence file: {output_path} ({duration}s)")
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to create silence: {e.stderr}")
            raise

    def _combine_audio_files_with_ffmpeg(self, file_list: List[Path], output_path: Path):
        """
        ffmpegã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ

        Args:
            file_list: çµåˆã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # concatç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            for file_path in file_list:
                # ffmpegã®concatã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                escaped_path = str(file_path).replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")
            concat_list_path = f.name

        try:
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_list_path,
                '-c', 'copy',
                '-y',
                str(output_path)
            ]

            result = subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
            self.logger.debug(f"Combined {len(file_list)} files to {output_path}")
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to combine audio files: {e.stderr}")
            raise
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            try:
                os.unlink(concat_list_path)
            except Exception:
                pass

    def _generate_with_punctuation_pause(self, text: str) -> Dict[str, Any]:
        """
        å¥ç‚¹ã§ã®é–“éš”åˆ¶å¾¡ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆ

        Args:
            text: ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            {
                'audio_base64': str,
                'alignment': {...}
            }
        """
        # è¨­å®šã‚’å–å¾—
        pause_duration = self.punctuation_pause_config.get("pause_duration", {})
        skip_section_end = self.punctuation_pause_config.get("skip_section_end", True)

        period_pause = pause_duration.get("period", 0.8)
        exclamation_pause = pause_duration.get("exclamation", 0.9)
        question_pause = pause_duration.get("question", 0.9)

        self.logger.info(
            f"Punctuation pause enabled: period={period_pause}s, "
            f"exclamation={exclamation_pause}s, question={question_pause}s"
        )

        # å¥ç‚¹ã§åˆ†å‰²
        segments = self._split_by_punctuation(text)

        if not segments:
            # åˆ†å‰²ã§ããªã‹ã£ãŸå ´åˆã¯ã€é€šå¸¸ã®å‡¦ç†
            self.logger.warning("No punctuation found, using normal generation")
            segments = [text]

        self.logger.info(f"Splitting text by punctuation: {len(segments)} segments")

        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        temp_dir = tempfile.mkdtemp(prefix='kokoro_punct_')
        temp_files = []

        try:
            # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
            for i, segment in enumerate(segments):
                if not segment.strip():
                    continue

                self.logger.info(f"Segment {i + 1}/{len(segments)}: {segment[:50]}...")

                # éŸ³å£°ç”Ÿæˆ
                audio_base64 = self._generate_single_audio(segment)
                audio_bytes = base64.b64decode(audio_base64)

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                segment_file = Path(temp_dir) / f"segment_{i:03d}.{self.response_format}"
                with open(segment_file, 'wb') as f:
                    f.write(audio_bytes)
                temp_files.append(segment_file)

                # ç„¡éŸ³ã‚’æŒ¿å…¥ï¼ˆæœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä»¥å¤–ã€ã¾ãŸã¯skip_section_end=falseã®å ´åˆï¼‰
                is_last = (i == len(segments) - 1)
                should_add_pause = not (is_last and skip_section_end)

                if should_add_pause:
                    # å¥èª­ç‚¹ã«å¿œã˜ãŸç„¡éŸ³æ™‚é–“ã‚’æ±ºå®š
                    if segment.endswith('ã€‚'):
                        silence_duration = period_pause
                    elif segment.endswith('ï¼'):
                        silence_duration = exclamation_pause
                    elif segment.endswith('ï¼Ÿ'):
                        silence_duration = question_pause
                    else:
                        silence_duration = 0.0

                    if silence_duration > 0:
                        silence_file = Path(temp_dir) / f"silence_{i:03d}.{self.response_format}"
                        self._create_silence_file(silence_duration, silence_file)
                        temp_files.append(silence_file)
                        self.logger.info(f"  + silence {silence_duration}s")

            # å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
            if not temp_files:
                raise ValueError("No audio segments generated")

            combined_file = Path(temp_dir) / f"combined.{self.response_format}"
            self._combine_audio_files_with_ffmpeg(temp_files, combined_file)

            self.logger.info(f"Combined {len(temp_files)} files")

            # çµåˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã«å¤‰æ›
            with open(combined_file, 'rb') as f:
                combined_audio_base64 = base64.b64encode(f.read()).decode('utf-8')

            # Whisperã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—
            alignment = self._extract_timestamps_with_whisper(combined_audio_base64, text)

            return {
                'audio_base64': combined_audio_base64,
                'alignment': alignment
            }

        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                import shutil
                shutil.rmtree(temp_dir)
                self.logger.debug(f"Cleaned up temp directory: {temp_dir}")
            except Exception as e:
                self.logger.warning(f"Failed to clean up temp directory {temp_dir}: {e}")

    def generate_with_timestamps(
        self,
        text: str,
        previous_text: Optional[str] = None,
        next_text: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Kokoro TTS + Whisperã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãéŸ³å£°ã‚’ç”Ÿæˆ

        å‡¦ç†ãƒ•ãƒ­ãƒ¼:
        1. Kokoro APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã—ï¼‰
        2. ç”Ÿæˆã—ãŸéŸ³å£°ã‚’Whisperã§è§£æã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—

        Args:
            text: ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            previous_text: å‰ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœªä½¿ç”¨ï¼‰
            next_text: æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœªä½¿ç”¨ï¼‰

        Returns:
            {
                'audio_base64': str,
                'alignment': {
                    'characters': List[str],
                    'character_start_times_seconds': List[float],
                    'character_end_times_seconds': List[float]
                }
            }
        """
        self.logger.info(f"Generating audio with timestamps: {text[:50]}...")

        # å¥ç‚¹ã§ã®é–“éš”åˆ¶å¾¡ãŒæœ‰åŠ¹ãªå ´åˆã¯å°‚ç”¨ã®å‡¦ç†ã‚’ä½¿ç”¨
        if self.punctuation_pause_config.get("enabled", False):
            return self._generate_with_punctuation_pause(text)

        # å¾“æ¥ã®å‡¦ç†ï¼ˆå¥ç‚¹åˆ¶å¾¡ãªã—ï¼‰
        # Step 1: Kokoro APIã§éŸ³å£°ã®ã¿ç”Ÿæˆ
        audio_base64 = self._generate_single_audio(text)

        self.logger.info(f"Audio generated successfully from Kokoro API ({len(audio_base64)} bytes base64)")

        # Step 2: Whisperã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—
        alignment = self._extract_timestamps_with_whisper(audio_base64, text)

        return {
            'audio_base64': audio_base64,
            'alignment': alignment
        }

    def _estimate_char_timings_from_duration(
        self,
        text: str,
        duration: float
    ) -> Dict[str, List]:
        """
        Whisperå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ–‡å­—æ•°æ¯”ç‡ã§ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ¨å®š

        Args:
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
            duration: éŸ³å£°ã®é•·ã•ï¼ˆç§’ï¼‰

        Returns:
            æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        """
        characters = list(text)
        char_count = len(characters)

        if char_count == 0:
            return {
                'characters': [],
                'character_start_times_seconds': [],
                'character_end_times_seconds': []
            }

        # å„æ–‡å­—ã®æ™‚é–“ã‚’å‡ç­‰åˆ†å‰²
        char_duration = duration / char_count

        start_times = []
        end_times = []

        for i in range(char_count):
            start_times.append(i * char_duration)
            end_times.append((i + 1) * char_duration)

        return {
            'characters': characters,
            'character_start_times_seconds': start_times,
            'character_end_times_seconds': end_times
        }

    def _expand_word_timings_to_chars(
        self,
        word_timings: List[Dict[str, Any]]
    ) -> Dict[str, List]:
        """
        å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ–‡å­—ãƒ¬ãƒ™ãƒ«ã«å±•é–‹

        å„å˜èªå†…ã§æ–‡å­—ã‚’å‡ç­‰ã«é…åˆ†ã—ã¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ¨å®š

        Args:
            word_timings: Whisperã‹ã‚‰å–å¾—ã—ãŸå˜èªã‚¿ã‚¤ãƒŸãƒ³ã‚°

        Returns:
            {
                'characters': List[str],
                'character_start_times_seconds': List[float],
                'character_end_times_seconds': List[float]
            }
        """
        characters = []
        start_times = []
        end_times = []

        for timing in word_timings:
            word = timing.get("word", "").strip()
            word_start = float(timing.get("start", 0.0))
            word_end = float(timing.get("end", 0.0))

            if not word:
                continue

            # å˜èªã®é•·ã•ï¼ˆæ–‡å­—æ•°ï¼‰
            word_length = len(word)

            if word_length == 0:
                continue

            # å„æ–‡å­—ã®æ™‚é–“å¹…ã‚’è¨ˆç®—ï¼ˆå‡ç­‰åˆ†å‰²ï¼‰
            word_duration = word_end - word_start
            char_duration = word_duration / word_length

            # å„æ–‡å­—ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç®—
            for i, char in enumerate(word):
                char_start = word_start + (i * char_duration)
                char_end = char_start + char_duration

                characters.append(char)
                start_times.append(char_start)
                end_times.append(char_end)

        return {
            'characters': characters,
            'character_start_times_seconds': start_times,
            'character_end_times_seconds': end_times
        }

    def _extract_timestamps_with_whisper(
        self,
        audio_base64: str,
        text: str
    ) -> Dict[str, List]:
        """
        éŸ³å£°ã‹ã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—

        ğŸ”¥ å¤‰æ›´ç‚¹: ElevenLabs Forced Alignmentã‚’å„ªå…ˆã—ã€å¤±æ•—æ™‚ã¯Whisperã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        Args:
            audio_base64: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆï¼‰

        Returns:
            alignmentå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±
        """
        # ğŸ”¥ æ–°è¦è¿½åŠ : ElevenLabs Forced Alignmentã‚’è©¦ã™
        if self.use_elevenlabs_fa and self.elevenlabs_aligner:
            try:
                self.logger.info("Extracting timing with ElevenLabs Forced Alignment...")

                # éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
                audio_bytes = base64.b64decode(audio_base64)

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(suffix=f".{self.response_format}", delete=False) as tmp:
                    tmp.write(audio_bytes)
                    tmp.flush()
                    os.fsync(tmp.fileno())
                    tmp_file_path = Path(tmp.name)

                try:
                    # ElevenLabs FAã§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ
                    alignment_result = self.elevenlabs_aligner.align(
                        audio_path=tmp_file_path,
                        text=text,
                        language="ja"
                    )

                    # æˆåŠŸã—ãŸã‚‰çµæœã‚’è¿”ã™
                    characters = alignment_result['characters']
                    char_start_times = alignment_result['char_start_times']
                    char_end_times = alignment_result['char_end_times']

                    self.logger.info(
                        f"âœ“ ElevenLabs FA successful: {len(characters)} characters, "
                        f"duration: {char_end_times[-1] if char_end_times else 0:.2f}s"
                    )

                    return {
                        'characters': characters,
                        'character_start_times_seconds': char_start_times,
                        'character_end_times_seconds': char_end_times
                    }

                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    if tmp_file_path.exists():
                        tmp_file_path.unlink()

            except Exception as e:
                self.logger.warning(
                    f"ElevenLabs Forced Alignment failed: {e}. "
                    "Falling back to Whisper..."
                )
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«é€²ã‚€

        # ğŸ”¥ Whisperãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        # WhisperãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯ç©ºã®alignmentã‚’è¿”ã™
        if not (self.whisper_config.get("enabled", True) and WHISPER_AVAILABLE):
            self.logger.warning("Whisper not available, returning empty alignment")
            return {
                'characters': [],
                'character_start_times_seconds': [],
                'character_end_times_seconds': []
            }

        # ğŸ”¥ è¿½åŠ ï¼šæ¯å›Whisperã‚’åˆæœŸåŒ–ï¼ˆå‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å½±éŸ¿ã‚’å®Œå…¨æ’é™¤ï¼‰
        try:
            self.logger.info("Initializing fresh Whisper model for this section...")
            whisper_extractor = WhisperTimingExtractor(
                model_name=self.whisper_config.get("model", "base"),
                logger=self.logger,
                language=self.whisper_config.get("language", "ja"),
                use_stable_ts=self.whisper_config.get("use_stable_ts", True),
                suppress_silence=self.whisper_config.get("suppress_silence", True),
                vad=self.whisper_config.get("vad", True),
                vad_threshold=self.whisper_config.get("vad_threshold", 0.35)
            )
        except Exception as e:
            self.logger.error(f"Failed to initialize Whisper: {e}")
            return {
                'characters': [],
                'character_start_times_seconds': [],
                'character_end_times_seconds': []
            }

        # éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        audio_bytes = base64.b64decode(audio_base64)

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        tmp_file = None
        try:
            with tempfile.NamedTemporaryFile(suffix=f".{self.response_format}", delete=False) as tmp:
                tmp.write(audio_bytes)
                tmp.flush()  # ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
                os.fsync(tmp.fileno())  # ãƒ‡ã‚£ã‚¹ã‚¯ã«å¼·åˆ¶æ›¸ãè¾¼ã¿
                tmp_file = tmp.name

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            file_size = os.path.getsize(tmp_file)
            expected_size = len(audio_bytes)
            if file_size != expected_size:
                raise IOError(
                    f"Temporary file incomplete: {file_size} bytes written, "
                    f"expected {expected_size} bytes"
                )

            self.logger.info(
                f"Extracting timestamps with Whisper from {tmp_file} "
                f"({file_size} bytes)"
            )

            # ğŸ”¥ å¤‰æ›´ï¼šwhisper_extractorã‚’ä½¿ç”¨ï¼ˆself.whisper_extractorã§ã¯ãªã„ï¼‰
            word_timings = whisper_extractor.extract_word_timings(
                audio_path=Path(tmp_file),
                text=text
            )

            # èªè­˜ç‡ã®è¨ºæ–­
            recognized_text = ''.join([w.get('word', '') for w in word_timings])
            expected_chars = len(text)
            recognized_chars = len(recognized_text)
            recognition_rate = recognized_chars / expected_chars if expected_chars > 0 else 0

            self.logger.info(
                f"Recognition rate: {recognition_rate:.1%} "
                f"({recognized_chars}/{expected_chars} chars)"
            )

            # èªè­˜ç‡ãŒ50%æœªæº€ã®å ´åˆã¯è­¦å‘Š
            if recognition_rate < 0.5:
                self.logger.warning(
                    f"Low recognition rate detected! Whisper may have failed. "
                    f"Expected text: {text[:50]}..."
                )
                self.logger.warning(
                    f"Recognized text: {recognized_text[:50]}..."
                )

            # å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ–‡å­—ãƒ¬ãƒ™ãƒ«ã«å±•é–‹
            expanded = self._expand_word_timings_to_chars(word_timings)
            characters = expanded['characters']
            start_times = expanded['character_start_times_seconds']
            end_times = expanded['character_end_times_seconds']

            self.logger.info(
                f"âœ“ Extracted {len(word_timings)} words with Whisper, "
                f"expanded to {len(characters)} characters, "
                f"duration: {end_times[-1] if end_times else 0:.2f}s"
            )

            return {
                'characters': characters,
                'character_start_times_seconds': start_times,
                'character_end_times_seconds': end_times
            }

        except Exception as e:
            self.logger.warning(f"Failed to extract timestamps with Whisper: {e}")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éŸ³å£°ã®é•·ã•ã‹ã‚‰æ¨å®š
            try:
                # ffprobeã§éŸ³å£°ã®é•·ã•ã‚’å–å¾—
                cmd = [
                    'ffprobe',
                    '-v', 'error',
                    '-show_entries', 'format=duration',
                    '-of', 'default=noprint_wrappers=1:nokey=1',
                    str(tmp_file)
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                duration = float(result.stdout.strip())

                self.logger.warning(
                    f"Using fallback: estimating timing from duration ({duration:.2f}s) "
                    f"and character count ({len(text)})"
                )

                return self._estimate_char_timings_from_duration(text, duration)
            except Exception as fallback_error:
                self.logger.error(f"Fallback also failed: {fallback_error}")
                # ç©ºã®alignmentã‚’è¿”ã™ï¼ˆéŸ³å£°ã¯ç”Ÿæˆæ¸ˆã¿ï¼‰
                return {
                    'characters': [],
                    'character_start_times_seconds': [],
                    'character_end_times_seconds': []
                }

        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if tmp_file and os.path.exists(tmp_file):
                try:
                    os.unlink(tmp_file)
                except Exception as e:
                    self.logger.warning(f"Failed to delete temporary file {tmp_file}: {e}")

    def generate_sections(
        self,
        sections: List[Dict[str, Any]],
        output_dir: Path,
        speed: float = 1.0
    ) -> List[Dict[str, Any]]:
        """
        è¤‡æ•°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®éŸ³å£°ã‚’ç”Ÿæˆ

        Args:
            sections: ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆ [{"section_id": int, "narration": str}]
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            speed: é€Ÿåº¦ï¼ˆ0.5-2.0ï¼‰

        Returns:
            [
                {
                    "section_id": int,
                    "audio_path": str,
                    "duration": float,
                    "timestamps": List[Dict],
                }
            ]
        """
        results = []

        for section in sections:
            section_id = section["section_id"]
            narration = section["narration"]

            # å‡ºåŠ›ãƒ‘ã‚¹
            output_path = output_dir / f"section_{section_id:02d}.mp3"

            # éŸ³å£°ç”Ÿæˆ
            self.logger.info(
                f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {section_id} ã‚’ç”Ÿæˆä¸­: {narration[:50]}..."
            )

            result = self.generate_with_timestamps(text=narration)

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            audio_bytes = base64.b64decode(result["audio_base64"])
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "wb") as f:
                f.write(audio_bytes)
            self.logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {output_path}")

            # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
            alignment = result["alignment"]
            char_end_times = alignment.get("character_end_times_seconds", [])
            duration = char_end_times[-1] if char_end_times else 0.0

            results.append({
                "section_id": section_id,
                "audio_path": str(output_path),
                "duration": duration,
                "alignment": alignment,
            })

        self.logger.info(f"{len(results)} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®éŸ³å£°ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        return results


# ========================================
# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
# ========================================

def test_kokoro_generator():
    """KokoroéŸ³å£°ç”Ÿæˆå™¨ã®å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    import tempfile

    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    try:
        generator = KokoroAudioGenerator(
            voice="af_bella",
            logger=logger
        )

        test_text = "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯Kokoro TTSã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚"

        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / "test.mp3"

            result = generator.generate_with_timestamps(text=test_text)

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            audio_bytes = base64.b64decode(result["audio_base64"])
            with open(output_path, "wb") as f:
                f.write(audio_bytes)

            print("\n" + "="*60)
            print("âœ“ ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            print("="*60)
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
            end_times = result['alignment']['character_end_times_seconds']
            print(f"éŸ³å£°é•·: {end_times[-1] if end_times else 0:.2f}ç§’")
            print(f"å˜èªæ•°: {len(result['alignment']['characters'])}")
            print(f"ã‚µã‚¤ã‚º: {output_path.stat().st_size / 1024:.1f}KB")

    except Exception as e:
        print(f"\nâœ— ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    test_kokoro_generator()
