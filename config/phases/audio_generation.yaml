# phase: audio generation
# ========================================
# Phase 2: 音声生成設定
# ========================================

# テキスト最適化設定
text_optimization:
  enabled: false                         # ⭐ Kokoro TTSは漢字を正確に読めるため無効化
  # Kokoro TTSはpyopenjtalkで漢字→音素変換が正確
  # 平仮名変換のオーバーヘッド（Claude API呼び出し）が不要
  # 元のnarrationテキストをそのまま使用することで：
  # - 処理速度が向上
  # - Claude APIコストが削減
  # - 字幕表示も元のテキストを使用
  model: "claude-sonnet-4-20250514"      # 使用するClaudeモデル（enabledがfalseの場合は未使用）
  use_context: true                      # 全体の文脈情報を活用（enabledがfalseの場合は未使用）

# 文脈制御設定
context_awareness:
  use_previous_text: true                # 前のセクションを文脈に使用
  use_next_text: true                    # 次のセクションを文脈に使用

# ========================================
# 音声生成サービス選択
# ========================================
# "kokoro": Kokoro TTS FastAPI（完全無料、タイムスタンプ対応）
# "elevenlabs": ElevenLabs API（高品質、有料）
service: "kokoro"

# ========================================
# Kokoro TTS 設定（service: "kokoro" の場合）
# ========================================
kokoro:
  # APIのベースURL（環境変数 KOKORO_API_URL で上書き可能）
  api_url: "http://localhost:8880"

  # 使用する音声名
  # 利用可能な日本語の声（Japanese Female）:
  # - jf_alpha ⭐推奨（日本語女性音声、自然）
  # 利用可能な英語の声（American Female）:
  # - af_bella （人気、安定）
  # - af_sarah （人気、自然）
  # - af_sky （明るめ）
  # - af_heart （落ち着き）
  # - af_alloy, af_aoede, af_jessica, af_kore, af_nicole, af_nova, af_river
  voice: "jf_alpha"

  # 速度（0.5-2.0）
  speed: 1.0

  # 出力フォーマット
  response_format: "mp3"  # mp3, wav, opus, flac

# ========================================
# Whisper タイムスタンプ取得設定
# ========================================
# Kokoro TTSは日本語のタイムスタンプに対応していないため、
# Whisperを使用して音声から単語レベルのタイミングを取得
whisper:
  enabled: true           # Whisper使用の有効化
  model: "small"         # tiny, base, small, medium, large
                         # small: 約500MB、高精度（日本語認識精度向上のため推奨）
                         # base: 約150MB、精度と速度のバランスが良い
                         # tiny: 約75MB、高速だが精度低め
  language: "ja"         # 日本語
  device: "auto"         # auto（自動検出）, cuda（GPU）, cpu

# ========================================
# ElevenLabs API設定（service: "elevenlabs" の場合）
# ========================================
# 日本語対応のvoice_id（以下から選択）:
# - "pNInz6obpgDQGcFmaJgB": Adam (多言語対応、男性)
# - "onwK4e9ZLuTAKqWW03F9": Daniel (多言語対応、男性)
# または、ElevenLabsダッシュボードで日本語対応の音声を確認してください
voice_id: "3JDquces8E8bkmvbh6Bc"  
model: "eleven_turbo_v2_5"  
with_timestamps: true  # タイムスタンプ付き音声生成を使用

# 音声品質設定
settings:
  stability: 0.7          # 0-1（低いほどバリエーション豊か）日本語は少し高めが良い
  similarity_boost: 0.75  # 0-1（高いほど元の声に近い）
  style: 0                # 0-1（スタイルの強さ）
  use_speaker_boost: true # スピーカーブースト有効化
  speed: 1.0              # 0.25-4.0（1.0が通常速度）

# 出力フォーマット
format:
  codec: "mp3_44100_128"  # mp3_44100_128 or mp3_44100_192
  sample_rate: 44100
  channels: 1  # モノラル

# セクション間の無音時間（秒）
inter_section_silence: 0.5

# リトライ設定
retry:
  max_attempts: 5
  delay_seconds: 10  # レート制限を考慮

# キャッシュ設定
cache:
  enabled: true
  use_cached_audio: true  # 同じナレーションならキャッシュを使用