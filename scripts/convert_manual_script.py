#!/usr/bin/env python3
"""
æ‰‹å‹•å°æœ¬ï¼ˆYAMLï¼‰ã‚’JSONå½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
    python scripts/convert_manual_script.py ã‚¤ã‚°ãƒŠãƒ¼ãƒ„ãƒ»ã‚¼ãƒ³ãƒ¡ãƒ«ãƒ¯ã‚¤ã‚¹

    ã¾ãŸã¯

    python scripts/convert_manual_script.py --all  # å…¨ã¦å¤‰æ›
"""

import yaml
import json
import re
import logging
from pathlib import Path
from datetime import datetime
import sys
import argparse

logger = logging.getLogger(__name__)


def safe_print(text: str):
    """çµµæ–‡å­—ã‚’å«ã‚€æ–‡å­—åˆ—ã‚’å®‰å…¨ã«å‡ºåŠ›ï¼ˆWindowsã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰"""
    try:
        print(text)
    except UnicodeEncodeError:
        # çµµæ–‡å­—ã‚’ASCIIæ–‡å­—ã«ç½®ãæ›ãˆ
        safe_text = text.replace('âœ…', '[OK]').replace('âŒ', '[ERROR]').replace('âš ï¸', '[WARNING]')
        print(safe_text)


class ScriptNormalizer:
    """YAMLå°æœ¬ã‚’å³å¯†ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ­£è¦åŒ–"""

    @staticmethod
    def extract_impact_sentences(text: str) -> tuple:
        """
        narrationã‹ã‚‰impact markersã‚’æŠ½å‡º
        
        ãƒãƒ¼ã‚«ãƒ¼å½¢å¼:
        - @@æ–‡ç« @@   : normalï¼ˆèµ¤ãƒ»70pxï¼‰
        - @@@æ–‡ç« @@@ : megaï¼ˆç‰¹å¤§ãƒ»ä¸­å¤®ã€Phase 2ã§å®Ÿè£…äºˆå®šï¼‰
        
        Args:
            text: å…ƒã®narrationï¼ˆãƒãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰
        
        Returns:
            (clean_text, impact_data)
            - clean_text: ãƒãƒ¼ã‚«ãƒ¼ã‚’å‰Šé™¤ã—ãŸnarrationï¼ˆTTSç”¨ï¼‰
            - impact_data: {"normal": [...], "mega": [...]}
        
        Example:
            å…¥åŠ›:
                "ã€Œã†ã¤ã‘è€…ã€ã¨å‘¼ã°ã‚ŒãŸã€‚
                 @@èª°ã‚‚ãŒä¾®ã£ãŸç”·ãŒã€é©å‘½å…ã¨ãªã£ãŸã€‚@@
                 ç¹”ç”°ä¿¡é•·ã¯å¤©ä¸‹ã‚’ç›®æŒ‡ã™ã€‚"
            
            å‡ºåŠ›:
                clean_text = "ã€Œã†ã¤ã‘è€…ã€ã¨å‘¼ã°ã‚ŒãŸã€‚\nèª°ã‚‚ãŒä¾®ã£ãŸç”·ãŒã€é©å‘½å…ã¨ãªã£ãŸã€‚\nç¹”ç”°ä¿¡é•·ã¯å¤©ä¸‹ã‚’ç›®æŒ‡ã™ã€‚"
                impact_data = {
                    "normal": ["èª°ã‚‚ãŒä¾®ã£ãŸç”·ãŒã€é©å‘½å…ã¨ãªã£ãŸã€‚"],
                    "mega": []
                }
        """
        impact_data = {"normal": [], "mega": []}
        
        # @@@...@@@ ã‚’æ¤œå‡ºï¼ˆmegaï¼‰- Phase 2ã§å®Ÿè£…äºˆå®š
        # æ³¨æ„: @@@ã‚’å…ˆã«ãƒã‚§ãƒƒã‚¯ã—ãªã„ã¨@@ã«ãƒãƒƒãƒã—ã¦ã—ã¾ã†
        mega_pattern = r'@@@(.+?)@@@'
        for match in re.finditer(mega_pattern, text, re.DOTALL):
            sentence = match.group(1).strip()
            # æ”¹è¡Œã‚’å«ã‚€å ´åˆã¯å‰Šé™¤
            sentence = sentence.replace('\n', '')
            if sentence:
                impact_data["mega"].append(sentence)
        
        # @@...@@ ã‚’æ¤œå‡ºï¼ˆnormalï¼‰
        normal_pattern = r'@@(.+?)@@'
        for match in re.finditer(normal_pattern, text, re.DOTALL):
            sentence = match.group(1).strip()
            # æ”¹è¡Œã‚’å«ã‚€å ´åˆã¯å‰Šé™¤
            sentence = sentence.replace('\n', '')
            # megaã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯
            if sentence and sentence not in impact_data["mega"]:
                impact_data["normal"].append(sentence)
        
        # ãƒãƒ¼ã‚«ãƒ¼ã‚’å‰Šé™¤ï¼ˆTTSã«å½±éŸ¿ã—ãªã„ã‚ˆã†ã«ï¼‰
        clean_text = re.sub(r'@@@(.+?)@@@', r'\1', text)  # megaå‰Šé™¤
        clean_text = re.sub(r'@@(.+?)@@', r'\1', clean_text)  # normalå‰Šé™¤
        
        return clean_text, impact_data

    @staticmethod
    def normalize_narration(text: str) -> tuple:
        """
        narrationãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ­£è¦åŒ– + impactæŠ½å‡º
        
        å‡¦ç†é †åº:
        1. ã¾ãšimpact markersã‚’æŠ½å‡ºï¼ˆãƒãƒ¼ã‚«ãƒ¼å‰Šé™¤ï¼‰
        2. ãã®å¾Œã€æ—¢å­˜ã®æ­£è¦åŒ–å‡¦ç†ï¼ˆç©ºè¡Œå‰Šé™¤ã€æ–‡æœ«ãƒã‚§ãƒƒã‚¯ç­‰ï¼‰
        
        Returns:
            (normalized_text, impact_data)
        
        Note:
            æ—¢å­˜ã®normalize_narrationãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ‹¡å¼µ
        """
        if not text:
            return text, {"normal": [], "mega": []}
        
        # 1. impact markersã‚’æŠ½å‡ºï¼ˆå…ˆã«ã‚„ã‚‹ï¼ï¼‰
        clean_text, impact_data = ScriptNormalizer.extract_impact_sentences(text)
        
        # 2. æ—¢å­˜ã®æ­£è¦åŒ–å‡¦ç†ï¼ˆç©ºè¡Œå‰Šé™¤ã€æ–‡æœ«ãƒã‚§ãƒƒã‚¯ç­‰ï¼‰
        lines = []
        for line in clean_text.split('\n'):
            line = line.strip()
            
            # ç©ºè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
            if not line:
                continue
            
            # æ–‡æœ«ãƒã‚§ãƒƒã‚¯
            if line.endswith('ã€‚') or line.endswith('ï¼'):
                lines.append(line)
            elif line.endswith('ã€'):
                lines.append(line + 'ã€‚')
            else:
                lines.append(line + 'ã€‚')
        
        result = '\n'.join(lines)
        result = re.sub(r'\n{2,}', '\n', result)
        
        return result, impact_data

    @staticmethod
    def normalize_thumbnail(thumbnail: dict) -> dict:
        """ã‚µãƒ ãƒã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–

        å‡¦ç†å†…å®¹:
        upper_text:
          - 1è¡Œã‚ãŸã‚Š3æ–‡å­—ã¾ã§
          - è¶…éã—ã¦ã„ã‚‹å ´åˆã¯è­¦å‘Šãƒ­ã‚°
          - 2è¡Œç›®ä»¥é™ã®å…ˆé ­ã«å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã€Œã€€ã€ã‚’è‡ªå‹•æŒ¿å…¥

        lower_text:
          - 1è¡Œã‚ãŸã‚Š5-7æ–‡å­—ï¼ˆæ¨å¥¨ï¼‰
          - ç¯„å›²å¤–ã®å ´åˆã¯è­¦å‘Šãƒ­ã‚°
          - 2è¡Œç›®ä»¥é™ã®å…ˆé ­ã«å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã€Œã€€ã€ã‚’è‡ªå‹•æŒ¿å…¥
        """
        if not thumbnail:
            return thumbnail

        # upper_textã®æ­£è¦åŒ–
        if "upper_text" in thumbnail:
            upper_lines = []
            for i, line in enumerate(thumbnail["upper_text"].split('\n')):
                line = line.strip()

                # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
                if len(line) > 3:
                    logger.warning(f"upper_textè¡ŒãŒ3æ–‡å­—è¶…é: {line} ({len(line)}æ–‡å­—)")

                # 2è¡Œç›®ä»¥é™ã¯å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’è¿½åŠ 
                if i > 0 and line:
                    line = 'ã€€' + line

                upper_lines.append(line)

            thumbnail["upper_text"] = '\n'.join(upper_lines)

        # lower_textã®æ­£è¦åŒ–
        if "lower_text" in thumbnail:
            lower_lines = []
            for i, line in enumerate(thumbnail["lower_text"].split('\n')):
                line = line.strip()

                # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆ5-7æ–‡å­—æ¨å¥¨ï¼‰
                if line and (len(line) < 5 or len(line) > 7):
                    logger.warning(f"lower_textè¡ŒãŒæ¨å¥¨ç¯„å›²å¤–: {line} ({len(line)}æ–‡å­—ã€æ¨å¥¨5-7æ–‡å­—)")

                # 2è¡Œç›®ä»¥é™ã¯å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’è¿½åŠ 
                if i > 0 and line:
                    line = 'ã€€' + line

                lower_lines.append(line)

            thumbnail["lower_text"] = '\n'.join(lower_lines)

        return thumbnail

    @staticmethod
    def normalize(data: dict) -> dict:
        """YAMLå…¨ä½“ã‚’æ­£è¦åŒ–ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        # ã‚µãƒ ãƒã‚¤ãƒ«ã‚’æ­£è¦åŒ–
        if "thumbnail" in data and data["thumbnail"]:
            data["thumbnail"] = ScriptNormalizer.normalize_thumbnail(data["thumbnail"])

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ­£è¦åŒ–ï¼ˆimpactæŠ½å‡ºã¯convert_yaml_to_jsonã§è¡Œã†ï¼‰
        if "sections" in data:
            for section in data["sections"]:
                # narrationã¯ã“ã“ã§ã¯æ­£è¦åŒ–ã—ãªã„ï¼ˆconvert_yaml_to_jsonã§impactæŠ½å‡ºã¨åŒæ™‚ã«è¡Œã†ï¼‰
                # bgm_suggestionã®ãƒã‚§ãƒƒã‚¯
                if "bgm" not in section or not section.get("bgm"):
                    section_id = section.get("section_id", "unknown")
                    logger.warning(f"Section {section_id}: bgm_suggestionãŒæœªè¨­å®šã§ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ'main'ã‚’ä½¿ç”¨ï¼‰")
                    section["bgm"] = "main"

        return data


def convert_yaml_to_json(yaml_path: Path, output_path: Path):
    """YAMLã‚’JSONã«å¤‰æ›"""

    # YAMLèª­ã¿è¾¼ã¿
    with open(yaml_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)

    # ğŸ”¥ æ­£è¦åŒ–å‡¦ç†
    normalizer = ScriptNormalizer()
    data = normalizer.normalize(data)

    # ã‚µãƒ ãƒã‚¤ãƒ«æƒ…å ±ã®å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    thumbnail_data = data.get("thumbnail")
    if thumbnail_data is None:
        safe_print(f"âš ï¸  Warning: 'thumbnail' field not found in {yaml_path.name}, using fallback values")
        thumbnail = {
            "upper_text": data["subject"],  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å‰äººå
            "lower_text": ""                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºæ–‡å­—
        }
    else:
        thumbnail = {
            "upper_text": thumbnail_data.get("upper_text", data["subject"]),
            "lower_text": thumbnail_data.get("lower_text", "")
        }
        # æ³¨: thumbnailå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã¯strip()ã—ãªã„ï¼ˆæ”¹è¡Œã‚³ãƒ¼ãƒ‰ \n ã‚’ä¿æŒã™ã‚‹ãŸã‚ï¼‰

    # JSONå½¢å¼ã«å¤‰æ›
    script_json = {
        "subject": data["subject"],
        "title": data["title"],
        "description": data["description"],
        "thumbnail": thumbnail,
        "sections": [],
        "total_estimated_duration": 0,
        "generated_at": datetime.now().isoformat(),
        "model_version": "manual"
    }

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¤‰æ›ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
    for section in data["sections"]:
        # narrationã‚’æ­£è¦åŒ– + impactæŠ½å‡º
        narration_text = section.get("narration", "")
        normalized_narration, impact_data = ScriptNormalizer.normalize_narration(narration_text)

        script_json["sections"].append({
            "section_id": section.get("section_id", 0),
            "title": section.get("title", ""),
            "narration": normalized_narration,  # â† ãƒãƒ¼ã‚«ãƒ¼å‰Šé™¤æ¸ˆã¿ï¼ˆTTSç”¨ï¼‰
            "estimated_duration": float(section.get("duration", 0)),
            "image_keywords": section.get("keywords", []),
            "atmosphere": section.get("atmosphere", ""),
            "requires_ai_video": False,
            "ai_video_prompt": None,
            "bgm_suggestion": section.get("bgm", ""),
            "impact_sentences": impact_data  # â† æ–°è¦è¿½åŠ ï¼
        })

        script_json["total_estimated_duration"] += section.get("duration", 0)

    # JSONä¿å­˜
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(script_json, f, indent=2, ensure_ascii=False)

    safe_print(f"âœ… Converted: {yaml_path.name} â†’ {output_path}")


def main():
    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.WARNING,
        format='[WARNING] %(message)s'
    )

    parser = argparse.ArgumentParser(description="æ‰‹å‹•å°æœ¬ã‚’JSONã«å¤‰æ›")
    parser.add_argument("subject", nargs="?", help="å‰äººå")
    parser.add_argument("--all", action="store_true", help="å…¨ã¦å¤‰æ›")
    args = parser.parse_args()

    manual_dir = Path("data/input/manual_scripts")
    output_dir = Path("data/input/manual_overrides")

    if args.all:
        # å…¨ã¦ã®YAMLã‚’å¤‰æ›
        yaml_files = list(manual_dir.glob("*.yaml"))
        if not yaml_files:
            safe_print(f"âŒ No YAML files found in {manual_dir}")
            sys.exit(1)

        for yaml_file in yaml_files:
            subject = yaml_file.stem
            output_path = output_dir / f"{subject}_script.json"
            convert_yaml_to_json(yaml_file, output_path)

        safe_print(f"\nâœ… Converted {len(yaml_files)} files")

    elif args.subject:
        # æŒ‡å®šã•ã‚ŒãŸå‰äººã®ã¿
        yaml_path = manual_dir / f"{args.subject}.yaml"
        output_path = output_dir / f"{args.subject}_script.json"

        if not yaml_path.exists():
            safe_print(f"âŒ File not found: {yaml_path}")
            sys.exit(1)

        convert_yaml_to_json(yaml_path, output_path)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
