#!/usr/bin/env python3
"""
Wikimediaæ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰

Wikimedia APIã®å„æ¤œç´¢æˆ¦ç•¥ã‚’å€‹åˆ¥ã«ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/simple_wikimedia_test.py "Oda Nobunaga"
"""

import sys
import requests
import json
import time
from pathlib import Path


def test_category_search(query: str):
    """ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*60)
    print("ãƒ†ã‚¹ãƒˆ: ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢")
    print("="*60)
    
    base_url = "https://commons.wikimedia.org/w/api.php"
    
    # User-Agentãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šï¼ˆå¿…é ˆï¼‰
    headers = {
        'User-Agent': 'VideoAutomation/1.0 (https://github.com/yourproject; test@example.com)'
    }
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢
    print(f"\n1. ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢: '{query}'")
    params = {
        'action': 'query',
        'list': 'search',
        'srsearch': f'Category:{query}',
        'srnamespace': 14,
        'srlimit': 5,
        'format': 'json'
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        categories = []
        if 'query' in data and 'search' in data['query']:
            categories = [item['title'] for item in data['query']['search']]
            
            print(f"âœ“ {len(categories)}ä»¶ã®ã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            for i, cat in enumerate(categories, 1):
                print(f"  {i}. {cat}")
        else:
            print("âœ— ã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        if not categories:
            return False
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: æœ€åˆã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        print(f"\n2. ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—: '{categories[0]}'")
        time.sleep(0.5)
        
        params = {
            'action': 'query',
            'list': 'categorymembers',
            'cmtitle': categories[0],
            'cmtype': 'file',
            'cmlimit': 10,
            'format': 'json'
        }
        
        response = requests.get(base_url, params=params, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if 'query' in data and 'categorymembers' in data['query']:
            files = data['query']['categorymembers']
            
            print(f"âœ“ {len(files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            for i, file in enumerate(files[:5], 1):  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                print(f"  {i}. {file['title']}")
            
            return len(files) > 0
        else:
            print("âœ— ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"âœ— ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    except Exception as e:
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_query_search(query: str):
    """ã‚¯ã‚¨ãƒªãƒ™ãƒ¼ã‚¹æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*60)
    print("ãƒ†ã‚¹ãƒˆ: ã‚¯ã‚¨ãƒªæ¤œç´¢")
    print("="*60)
    
    base_url = "https://commons.wikimedia.org/w/api.php"
    
    # User-Agentãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šï¼ˆå¿…é ˆï¼‰
    headers = {
        'User-Agent': 'VideoAutomation/1.0 (https://github.com/yourproject; test@example.com)'
    }
    
    print(f"\nã‚¯ã‚¨ãƒªã§æ¤œç´¢: 'File:{query}'")
    params = {
        'action': 'query',
        'generator': 'search',
        'gsrsearch': f'File:{query}',
        'gsrnamespace': 6,
        'gsrlimit': 10,
        'prop': 'imageinfo',
        'iiprop': 'url|size',
        'format': 'json'
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if 'query' in data and 'pages' in data['query']:
            pages = data['query']['pages']
            
            print(f"âœ“ {len(pages)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            for i, (page_id, page) in enumerate(list(pages.items())[:5], 1):
                title = page.get('title', 'Unknown')
                print(f"  {i}. {title}")
                
                if 'imageinfo' in page:
                    info = page['imageinfo'][0]
                    width = info.get('width', 0)
                    height = info.get('height', 0)
                    print(f"     ã‚µã‚¤ã‚º: {width}x{height}")
            
            return len(pages) > 0
        else:
            print("âœ— ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"âœ— ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    except Exception as e:
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_japanese_vs_english():
    """æ—¥æœ¬èªã¨è‹±èªã®æ¤œç´¢çµæœã‚’æ¯”è¼ƒ"""
    print("\n" + "="*60)
    print("ãƒ†ã‚¹ãƒˆ: æ—¥æœ¬èª vs è‹±èª")
    print("="*60)
    
    test_cases = [
        ("ç¹”ç”°ä¿¡é•·", "Oda Nobunaga"),
        ("å¾³å·å®¶åº·", "Tokugawa Ieyasu"),
    ]
    
    results = []
    
    for japanese, english in test_cases:
        print(f"\n\n{'â”€'*60}")
        print(f"æ¯”è¼ƒ: {japanese} vs {english}")
        print('â”€'*60)
        
        # æ—¥æœ¬èªã§æ¤œç´¢
        print(f"\n[æ—¥æœ¬èª] {japanese}")
        jp_success = test_category_search(japanese)
        jp_count = "æˆåŠŸ" if jp_success else "å¤±æ•—"
        
        time.sleep(1)
        
        # è‹±èªã§æ¤œç´¢
        print(f"\n[è‹±èª] {english}")
        en_success = test_category_search(english)
        en_count = "æˆåŠŸ" if en_success else "å¤±æ•—"
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        results.append({
            'japanese': japanese,
            'english': english,
            'jp_result': jp_count,
            'en_result': en_count
        })
        
        time.sleep(1)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n\n" + "="*60)
    print("çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)
    
    for result in results:
        print(f"\n{result['japanese']} / {result['english']}")
        print(f"  æ—¥æœ¬èª: {result['jp_result']}")
        print(f"  è‹±èª: {result['en_result']}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "ğŸ” "*20)
    print("Wikimediaæ¤œç´¢ç²¾åº¦ãƒ†ã‚¹ãƒˆ")
    print("ğŸ” "*20)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
    if len(sys.argv) > 1:
        query = sys.argv[1]
        print(f"\næ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {query}\n")
        
        # ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢
        cat_success = test_category_search(query)
        time.sleep(1)
        
        # ã‚¯ã‚¨ãƒªæ¤œç´¢
        query_success = test_query_search(query)
        
        # çµæœã‚µãƒãƒªãƒ¼
        print("\n\n" + "="*60)
        print("çµæœ")
        print("="*60)
        print(f"ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢: {'âœ“ æˆåŠŸ' if cat_success else 'âœ— å¤±æ•—'}")
        print(f"ã‚¯ã‚¨ãƒªæ¤œç´¢: {'âœ“ æˆåŠŸ' if query_success else 'âœ— å¤±æ•—'}")
        
        if cat_success:
            print("\næ¨å¥¨: ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼ˆæœ€ã‚‚æ­£ç¢ºï¼‰")
        elif query_success:
            print("\næ¨å¥¨: ã‚¯ã‚¨ãƒªæ¤œç´¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼ˆã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
        else:
            print("\nâš  ã©ã¡ã‚‰ã®æ–¹æ³•ã§ã‚‚çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            print("  - æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„")
            print("  - è‹±èªåã§è©¦ã—ã¦ãã ã•ã„")
    
    else:
        # æ—¥æœ¬èª vs è‹±èªã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
        test_japanese_vs_english()
        
        print("\n\n" + "="*60)
        print("çµè«–")
        print("="*60)
        print("âœ“ è‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™")
        print("âœ“ ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢ãŒæœ€ã‚‚æ­£ç¢ºã§ã™")
        print("\nä½¿ã„æ–¹:")
        print("  python scripts/simple_wikimedia_test.py 'Oda Nobunaga'")


if __name__ == "__main__":
    main()